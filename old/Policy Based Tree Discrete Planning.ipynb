{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random as npr, random as r\n",
    "import tensorflow as tf  \n",
    "from NavTask import NavigationTask\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.slim as slim\n",
    "from forwardModel3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Node --> Children  \n",
    "\n",
    "# From: https://github.com/ericjang/gumbel-softmax\n",
    "class GumbelSoftmax(object):\n",
    "    def sample_gumbel(shape, eps=1e-20): \n",
    "      \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "      \"\"\"  dd \"\"\"\n",
    "      U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "      return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(logits, temperature): \n",
    "      \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "      y = logits + GumbelSoftmax.sample_gumbel(tf.shape(logits))\n",
    "      return tf.nn.softmax( y / temperature)\n",
    "\n",
    "    def gumbel_softmax(logits, temperature, hard=False):\n",
    "      \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "      Args:\n",
    "        logits: [batch_size, n_class] unnormalized log-probs\n",
    "        temperature: non-negative scalar\n",
    "        hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "      Returns:\n",
    "        [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "        If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "        be a probabilitiy distribution that sums to 1 across classes\n",
    "      \"\"\"\n",
    "      y = GumbelSoftmax.gumbel_softmax_sample(logits, temperature)\n",
    "      if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "      return y\n",
    "\n",
    "#sess = tf.Session()\n",
    "#sess.run(GumbelSoftmax.gumbel_softmax(tf.constant([[0.5, 0.5]]), 0.5, hard=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimulationPolicy(object):\n",
    "    \n",
    "    def __init__(self, obs_space, act_space, h_size=100):\n",
    "        print(\"Observation Space: \" , obs_space)\n",
    "        print(\"Action Space: \", act_space)\n",
    "        self.h_size = h_size\n",
    "        # Input space: [Episode_length, observations], output:[Episode_Length,action_space]\n",
    "        self.input = tf.placeholder(tf.float32, [None] + list(obs_space))\n",
    "        self.act_space = act_space\n",
    "        #self.output = self.getSoftAction(self.input)\n",
    "        self.sampleOutput = self.sample(self.input)\n",
    "        self.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"softaction\")#tf.get_variable_scope().name) \n",
    "    \n",
    "    def getSoftAction(self,observation, reuse=None):\n",
    "        with tf.variable_scope(\"softaction\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(observation, self.h_size, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            return slim.fully_connected(hidden, self.act_space, activation_fn=tf.nn.softmax, biases_initializer=None)\n",
    "        \n",
    "    def sample(self,observation,temperature=0.5, reuse=None):\n",
    "        sess = tf.get_default_session()\n",
    "        #print(sess.run(tf.report_uninitialized_variables()))\n",
    "        softAction = self.getSoftAction(observation, reuse=reuse)\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        return GumbelSoftmax.gumbel_softmax(softAction, temperature, hard=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-f472e804f3d8>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-f472e804f3d8>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    x, _ = sess.run([sample)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    simpolicy = SimulationPolicy( np.shape([1,1]),3)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample = simpolicy.sample(tf.constant([[5.0,1.0]]), reuse=True) \n",
    "    #sample1 = simpolicy.sample(tf.constant([[5.0,1.0]]), reuse=True)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    x, _ = sess.run([sample)\n",
    "    #writer.close()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, parent_node, state, action):\n",
    "        self.parent = parent_node\n",
    "        self.children = []\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        \n",
    "    def addChild(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self,initialState,forwardModel,simPolicy,maxDepth=5,branchingFactor=3):\n",
    "        self.simPolicy = simPolicy\n",
    "        self.maxDepth, self.branchFactor = maxDepth, branchingFactor\n",
    "        self.forwardModel = forwardModel\n",
    "        parent = Node(None,initialState,None)\n",
    "        self.allStates = [initialState]\n",
    "        self.allActions = []\n",
    "\n",
    "        print('Generating growth')\n",
    "        # Generate Tree\n",
    "        self.tree_head = self.grow(parent,0,self.branchFactor)\n",
    "        self.tAllStates = tf.stack(self.allStates)\n",
    "        # Get leaves\n",
    "        print('Getting leaves')\n",
    "        q, self.leaves = [ parent ], []\n",
    "        while len(q) >= 1:\n",
    "            currNode = q.pop()\n",
    "            for child in currNode.children:\n",
    "                if len( child.children ) == 0: self.leaves.append( child )\n",
    "                else: q.append( child )\n",
    "        print(self.leaves)\n",
    "    \n",
    "    def getPathFromLeaf(self,leafNumber):\n",
    "        sess = tf.get_default_session()\n",
    "        leaf = self.leaves[leafNumber]\n",
    "        path = [sess.run( leaf.state )]\n",
    "        actions = [sess.run( leaf.action )]\n",
    "        currNode = leaf\n",
    "        while not currNode.parent is None:\n",
    "            print(currNode.state)\n",
    "            path.append(sess.run( currNode.parent.state ))\n",
    "            if not currNode.parent.action is None:\n",
    "                actions.append(sess.run( currNode.parent.action ))\n",
    "            currNode = currNode.parent\n",
    "        return (list(reversed(path)),list(reversed(actions)))\n",
    "    \n",
    "    def grow(self,node,d,b):\n",
    "        print('Grow',d,node.state)\n",
    "        if d == self.maxDepth : return node\n",
    "        for i in range(b):\n",
    "            # Sample the current action\n",
    "            a_s = self.simPolicy.sample(node.state,reuse=True)\n",
    "            print(\"a_s\",a_s,d,\"  b\",i)\n",
    "            a_s = tf.Print(a_s, [a_s], message=\"a_s\")\n",
    "            # Compute the predicted forward state\n",
    "            concat_vec = tf.concat([tf.squeeze(tf.cast(node.state,dtype=tf.float32)),tf.squeeze(a_s)], axis=0)\n",
    "            concat_vec = tf.reshape(concat_vec,[1,1,74]) #[batch size, sequence length, size of concat_vec]\n",
    "            state_out = self.forwardModel.get_initial_features(1)\n",
    "            concat_vec = tf.Print(concat_vec,[concat_vec], message=\"concat_vec\")\n",
    "            print(\"concat_vec\",concat_vec,d)\n",
    "            current_state,state_out = self.forwardModel.dynamic_cell(concat_vec, tf.constant([1]), state_out)\n",
    "            c1 = tf.nn.softmax(current_state[0,0:15])\n",
    "            c2 = tf.nn.softmax(current_state[0,15:30])\n",
    "            c3 = tf.nn.softmax(current_state[0,30:34])\n",
    "            c4 = tf.nn.softmax(current_state[0,34:49])\n",
    "            c5 = tf.nn.softmax(current_state[0,49:64])\n",
    "            current_state = tf.reshape(tf.concat([c1,c2,c3,c4,c5],axis=-1),(1,64))\n",
    "            # Build the next subtree\n",
    "            current_state = tf.Print(current_state, [current_state],message=\"current_state\")\n",
    "            self.allStates.append(current_state)\n",
    "            self.allActions.append(a_s)\n",
    "            print(\"curr_state\",current_state,d)\n",
    "            node.addChild( self.grow( Node(node, current_state, a_s), d+1, b) )\n",
    "        return node\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.] [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "INFO:tensorflow:Restoring parameters from abcd.ckpt\n",
      "Observation Space:  (64,)\n",
      "Action Space:  10\n",
      "[array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)]\n",
      "Concat Tensor(\"Reshape:0\", shape=(1, 1, 74), dtype=float32)\n",
      "[ 18.28815842   3.44512892   0.39294881   2.30822229   4.26065636\n",
      "   3.61674213   0.76037085  -2.29738641  -3.92539024  -5.13367653\n",
      "  -2.06606674  -5.40129995  -0.14776307  -0.34613228  -8.5389452\n",
      "   7.99837875  -2.93729758  -0.49253488  -1.77298999   0.60460484\n",
      "  -2.79091978   0.18809783  -2.47328424  -1.35024357  -4.69795704\n",
      "  -2.70827985  -0.12187338   0.36789912  -2.42670369  -0.71769559\n",
      "  25.29188919  -5.46745872  -6.1435647   -3.28590918  -1.07907701\n",
      "   0.0375042   -7.70297575  -2.95997119  -4.289814    -4.69106913\n",
      "  -0.31883267   1.54537022  -6.47672081  -0.05635498  -4.20820808\n",
      "  -7.18692398  -4.64505529  -4.91750002   8.6741209   -6.46207333\n",
      "  -2.86831856  -5.87697983  -7.12506008  -4.05570555  -7.25973749\n",
      "  -5.55127811  -4.84075975  -3.18866467  -1.50752759  -5.85568905\n",
      " -10.10552406  -3.69050932  -3.75832915   7.71020365]\n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---\n",
      "Generating growth\n",
      "Grow 0 Tensor(\"Cast_2:0\", shape=(1, 64), dtype=float32)\n",
      "a_s Tensor(\"add_7:0\", shape=(1, 10), dtype=float32) 0   b 0\n",
      "concat_vec Tensor(\"Print_1:0\", shape=(1, 1, 74), dtype=float32) 0\n",
      "curr_state Tensor(\"Print_2:0\", shape=(?, 64), dtype=float32) 0\n",
      "Grow 1 Tensor(\"Print_2:0\", shape=(?, 64), dtype=float32)\n",
      "a_s Tensor(\"add_11:0\", shape=(?, 10), dtype=float32) 1   b 0\n",
      "concat_vec Tensor(\"Print_4:0\", shape=(1, 1, 74), dtype=float32) 1\n",
      "curr_state Tensor(\"Print_5:0\", shape=(?, 64), dtype=float32) 1\n",
      "Grow 2 Tensor(\"Print_5:0\", shape=(?, 64), dtype=float32)\n",
      "Getting leaves\n",
      "[<__main__.Node object at 0x000001728E975BE0>]\n",
      "Running\n",
      "[[ 45.6890831   14.47794914  20.94565582  12.04973698  12.78029633\n",
      "    2.49282575   2.48722816  -1.6912241   -6.70399523  -8.36397934\n",
      "   -2.28931737 -13.59576797   1.21190429  -8.59954453 -24.04296494\n",
      "   15.64218712  -2.37938905  10.65253448  -3.51222014  -2.09338784\n",
      "    1.97916412  -3.28299499   1.81071818  -5.37088871  -1.37833858\n",
      "    3.73927116  -1.70716047  -2.0716145   -6.7254715   -5.15257263\n",
      "   -2.36764288  -4.77430153  12.31043148  -2.77175665  -3.29033089\n",
      "   -7.88770866  -6.72712517  -2.10615969  -4.94513416  -3.42503834\n",
      "   -7.84451628  -1.63162279 -12.51382256   0.70543557  -4.36998749\n",
      "   -8.88896847  -8.49954605  -4.37013435  11.19774246  -8.02508736\n",
      "   -9.28864002 -13.75295544 -10.46308136 -10.59204197 -18.83140182   3.5632\n",
      "  -16.32194519  -7.50200272 -14.41274834 -11.98125458  -7.22056675\n",
      "   -8.46346951 -13.18007946  11.97198868]]\n"
     ]
    }
   ],
   "source": [
    "env = NavigationTask() \n",
    "state_i=env.getStateRep()\n",
    "observation_space = np.shape(state_i)\n",
    "#get goal state\n",
    "state_f=env.getStateRep()\n",
    "inds = np.cumsum([0,env.w,env.h,len(env.oriens),env.w,env.h])\n",
    "state_f[inds[0]:inds[1]] = env._intToOneHot(env.goal_pos[0],env.w)\n",
    "state_f[inds[1]:inds[2]] = env._intToOneHot(env.goal_pos[1],env.h)\n",
    "num_of_actions = 10\n",
    "print(state_i, state_f)\n",
    "\n",
    "tree = None\n",
    "path = None\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    forwardModel=ForwardModel(64,74,10, 100)\n",
    "    forwardModel.load_model('abcd.ckpt')\n",
    "    simpolicy = SimulationPolicy( observation_space ,num_of_actions)\n",
    "    reshape_state = np.reshape(state_i,(1,-1))\n",
    "    sess.run(tf.variables_initializer(simpolicy.trainable_vars))\n",
    "    a_s = sess.run([simpolicy.sampleOutput], {simpolicy.input: reshape_state})\n",
    "    #a_s = [[0.,0.,1.,0,0,0,0,0,0,0]]\n",
    "    \n",
    "    print(a_s)\n",
    "    concat_vec = tf.concat([tf.cast(state_i,dtype=tf.float32),tf.squeeze(a_s[0])], axis=0)\n",
    "    concat_vec = tf.reshape(concat_vec,[-1,1,74]) #[batch size, sequence length, size of concat_vec]\n",
    "    print(\"Concat\", concat_vec)\n",
    "    state_out = forwardModel.get_initial_features(1)\n",
    "    current_state,state_out = forwardModel.dynamic_cell(concat_vec, tf.constant([1]), state_out)\n",
    "    output = sess.run([current_state])[0][0]\n",
    "    print(output)\n",
    "    print(np.argmax(output[0:15]))\n",
    "    print(np.argmax(output[15:30]))\n",
    "    print(np.argmax(output[30:34]))\n",
    "    print(np.argmax(output[34:49]))\n",
    "    print(np.argmax(output[49:64]))\n",
    "    \n",
    "    print(np.argmax(state_i[0:15]))\n",
    "    print(np.argmax(state_i[15:30]))\n",
    "    print(np.argmax(state_i[30:34]))\n",
    "    print(np.argmax(state_i[34:49]))\n",
    "    print(np.argmax(state_i[49:64]))\n",
    "    \n",
    "    print('---')\n",
    "    tree = Tree(tf.cast(reshape_state,dtype=tf.float32),forwardModel,simpolicy,2,1)\n",
    "    \n",
    "#     leaves = tree.leaves\n",
    "#     print(\"len\",len(leaves))\n",
    "#     for i,leaf in enumerate(leaves):\n",
    "#         print(i,leaf.state)\n",
    "        \n",
    "    print('Running')\n",
    "    qq = sess.run(tree.leaves[0].state)  \n",
    "    print(qq)\n",
    "#     print('Getting path')\n",
    "#     path = tree.getPathFromLeaf(0)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f701d3b8b14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "states,actions = path\n",
    "for i,state in enumerate(states):\n",
    "    state = state[0]\n",
    "    print(np.argmax(state[0:15]))\n",
    "    print(np.argmax(state[15:30]))\n",
    "    print(np.argmax(state[30:34]))\n",
    "    print(np.argmax(state[34:49]))\n",
    "    print(np.argmax(state[49:64]))\n",
    "    if i <= len(actions) - 1:\n",
    "        print(\"A:\",actions[i])\n",
    "    print(\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.] [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "INFO:tensorflow:Restoring parameters from abcd.ckpt\n",
      "Observation Space:  (64,)\n",
      "Action Space:  10\n",
      "Generating growth\n",
      "Grow 0 Tensor(\"Placeholder_4:0\", shape=(1, 64), dtype=float32)\n",
      "a_s Tensor(\"add_7:0\", shape=(1, 10), dtype=float32) 0   b 0\n",
      "concat_vec Tensor(\"Print_1:0\", shape=(1, 1, 74), dtype=float32) 0\n",
      "curr_state Tensor(\"Print_2:0\", shape=(1, 64), dtype=float32) 0\n",
      "Grow 1 Tensor(\"Print_2:0\", shape=(1, 64), dtype=float32)\n",
      "a_s Tensor(\"add_11:0\", shape=(1, 10), dtype=float32) 1   b 0\n",
      "concat_vec Tensor(\"Print_4:0\", shape=(1, 1, 74), dtype=float32) 1\n",
      "curr_state Tensor(\"Print_5:0\", shape=(1, 64), dtype=float32) 1\n",
      "Grow 2 Tensor(\"Print_5:0\", shape=(1, 64), dtype=float32)\n",
      "Getting leaves\n",
      "[<__main__.Node object at 0x000001729D896828>]\n",
      "Running\n",
      "[[[  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "     0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "\n",
      " [[  9.97990966e-01   9.43783671e-04   5.43304486e-05   6.78443816e-04\n",
      "     2.63373251e-04   5.44193281e-05   2.95916084e-06   5.12152610e-06\n",
      "     3.72963513e-07   1.18069172e-08   5.70976044e-06   3.55481973e-07\n",
      "     5.50493802e-08   1.26165261e-07   1.68188163e-09   2.56154537e-01\n",
      "     2.58074637e-04   2.52157133e-02   3.76811713e-01   1.15339244e-02\n",
      "     7.94092007e-03   7.13598775e-03   5.59042674e-03   2.15682816e-02\n",
      "     4.85210726e-03   8.24500283e-04   4.07700911e-02   3.47942929e-03\n",
      "     2.69616907e-03   2.35168040e-01   9.96339440e-01   1.97665008e-06\n",
      "     3.09738284e-03   5.61173074e-04   2.02205320e-06   5.50877701e-07\n",
      "     2.31160485e-07   3.20516136e-07   3.93093501e-07   1.31995961e-07\n",
      "     1.62380343e-06   3.25443689e-05   3.79442042e-08   2.97374254e-06\n",
      "     3.69538583e-07   1.46302526e-07   7.75306319e-07   1.80965756e-07\n",
      "     9.99957681e-01   1.71428246e-06   9.07068568e-07   3.46680338e-07\n",
      "     6.73681200e-08   2.90297208e-07   4.01994953e-08   1.14811874e-05\n",
      "     1.02028434e-06   5.70778525e-07   6.20491960e-07   6.84433417e-07\n",
      "     1.45931637e-07   4.50095627e-07   7.09635060e-07   9.99980927e-01]]\n",
      "\n",
      " [[  9.99998212e-01   1.27648480e-06   3.07209049e-08   3.34670972e-07\n",
      "     5.37216174e-08   6.46812381e-08   3.52298496e-10   2.94399644e-10\n",
      "     4.77613088e-12   2.55052351e-11   2.70298034e-10   2.74111810e-11\n",
      "     8.60292504e-10   3.80839982e-09   9.34301735e-14   1.36436184e-03\n",
      "     2.08045196e-04   1.16854964e-03   1.01357974e-01   4.94699285e-04\n",
      "     2.53375294e-03   7.87602551e-03   3.65163269e-03   1.92386322e-02\n",
      "     1.60200056e-02   1.09212836e-02   5.48583984e-01   1.18792564e-01\n",
      "     3.50754857e-02   1.32712960e-01   2.56760741e-05   9.99974370e-01\n",
      "     4.65063099e-09   6.77097889e-09   4.18875834e-06   2.22010135e-06\n",
      "     6.38356710e-08   1.34654854e-07   9.33241336e-06   3.93886785e-06\n",
      "     1.15133844e-06   6.18363219e-06   1.59653570e-08   3.85306612e-06\n",
      "     5.78275785e-06   2.71202271e-06   3.02117087e-07   1.46340270e-07\n",
      "     9.99959946e-01   3.54596114e-06   3.60988488e-05   3.43953076e-07\n",
      "     8.23941809e-06   3.56998453e-06   3.20735722e-08   1.61302671e-06\n",
      "     2.88238843e-05   2.82595593e-05   2.24408184e-04   2.17344405e-06\n",
      "     1.09265534e-06   1.25407561e-04   7.04418835e-06   9.99529362e-01]]]\n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "A: [[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
      "--\n",
      "0\n",
      "3\n",
      "0\n",
      "14\n",
      "14\n",
      "A: [[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "--\n",
      "0\n",
      "11\n",
      "1\n",
      "14\n",
      "14\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "env = NavigationTask() \n",
    "state_i=env.getStateRep()\n",
    "observation_space = np.shape(state_i)\n",
    "#get goal state\n",
    "state_f=env.getStateRep()\n",
    "inds = np.cumsum([0,env.w,env.h,len(env.oriens),env.w,env.h])\n",
    "state_f[inds[0]:inds[1]] = env._intToOneHot(env.goal_pos[0],env.w)\n",
    "state_f[inds[1]:inds[2]] = env._intToOneHot(env.goal_pos[1],env.h)\n",
    "num_of_actions = 10\n",
    "print(state_i, state_f)\n",
    "\n",
    "tree = None\n",
    "path = None\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    forwardModel=ForwardModel(64,74,10, 100)\n",
    "    forwardModel.load_model('abcd.ckpt')\n",
    "    simpolicy = SimulationPolicy( observation_space ,num_of_actions)\n",
    "    sess.run(tf.variables_initializer(simpolicy.trainable_vars))\n",
    "    \n",
    "    inital_state = tf.placeholder(tf.float32, [1,64])\n",
    "    tree = Tree(tf.cast(inital_state,dtype=tf.float32),forwardModel,simpolicy,2,1)\n",
    "    \n",
    "#     leaves = tree.leaves\n",
    "#     print(\"len\",len(leaves))\n",
    "#     for i,leaf in enumerate(leaves):\n",
    "#         print(i,leaf.state)\n",
    "    reshape_state = np.reshape(state_i,(1,-1))\n",
    "    print('Running')\n",
    "    qq, actions = sess.run([tree.tAllStates, tree.allActions], {inital_state:reshape_state})  \n",
    "    print(qq)\n",
    "    \n",
    "    for i,state in enumerate(qq):\n",
    "        state = state[0]\n",
    "        print(np.argmax(state[0:15]))\n",
    "        print(np.argmax(state[15:30]))\n",
    "        print(np.argmax(state[30:34]))\n",
    "        print(np.argmax(state[34:49]))\n",
    "        print(np.argmax(state[49:64]))\n",
    "        if i <= len(actions) - 1:\n",
    "            print(\"A:\",actions[i])\n",
    "        print(\"--\")\n",
    "#     print('Getting path')\n",
    "#     path = tree.getPathFromLeaf(0)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
