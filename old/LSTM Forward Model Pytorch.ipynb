{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.autograd as autograd\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable as avar\n",
    "    \n",
    "from SimpleTask import SimpleGridTask\n",
    "from TransportTask import TransportTask\n",
    "from NavTask import NavigationTask\n",
    "from SeqData import SeqData\n",
    "\n",
    "import os, sys, pickle, numpy as np, numpy.random as npr, random as r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pytorch LSTM input: Sequence * Batch * Input\n",
    "\n",
    "class LSTMForwardModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputSize, stateSize, h_size=400, nlayers=1):\n",
    "        super(LSTMForwardModel, self).__init__()\n",
    "        self.hdim, self.stateSize, self.nlayers, self.inputSize, self.actionSize = h_size, stateSize, nlayers, inputSize, inputSize - stateSize\n",
    "        self.lstm = nn.LSTM(input_size=inputSize, hidden_size=self.hdim, num_layers=nlayers)\n",
    "        self.hiddenToState = nn.Linear(self.hdim, stateSize)\n",
    "        self.reInitialize(1)\n",
    "        \n",
    "    def reInitialize(self, batch_size):\n",
    "        # Size = (num_layers, minibatch_size, hidden_dim)\n",
    "        self.hidden = (avar(torch.zeros(self.nlayers,batch_size,self.hdim)), avar(torch.zeros(self.nlayers,batch_size,self.hdim)))\n",
    "        \n",
    "    def forward(self, inital_state, actions, seqn):\n",
    "        #initalState [1*1*state_size] actions[batch*noOfActions*Action_size] \n",
    "        #print(actions[0].shape)\n",
    "        #print(seqn)\n",
    "        int_states = []\n",
    "        \n",
    "        current_state = avar(torch.from_numpy(inital_state).float())\n",
    "        #print(current_state.shape)\n",
    "        #print(torch.cat((current_state, actions[0]),0))\n",
    "        for i in range(seqn):\n",
    "            concat_vec = torch.cat((current_state, actions[i]),0).view(1,1,-1)\n",
    "            lstm_out, self.hidden = self.lstm(concat_vec, self.hidden)\n",
    "            output_state = self.hiddenToState(lstm_out[0,0,:])\n",
    "            int_states.append(output_state)\n",
    "            current_state = output_state\n",
    "            \n",
    "        return current_state, int_states\n",
    "    \n",
    "    def train(self, trainSeq, validSeq, nEpochs=1500, epochLen=500, validateEvery=20, vbs=500, printEvery=5, noiseSigma=0.4):\n",
    "        optimizer = optim.Adam(self.parameters(), lr = 0.003)\n",
    "        state_size, action_size, tenv = self.stateSize, self.actionSize, trainSeq.env\n",
    "        for epoch in range(nEpochs):\n",
    "            if epoch % printEvery == 0: print('Epoch:',epoch, end='')\n",
    "            loss = 0.0\n",
    "            self.zero_grad() # Zero out gradients\n",
    "            for i in range(epochLen):\n",
    "                self.reInitialize(1) # Reset LSTM hidden state\n",
    "                seq,label = trainSeq.randomTrainingPair() # Current value\n",
    "                actions = [ s[64:74]  for s in seq ]\n",
    "                actions = [ avar(torch.from_numpy(s).float()) for s in actions] \n",
    "                intial_state = seq[0][0:64]\n",
    "                seqn = len(seq)\n",
    "                prediction, _ = self.forward(intial_state,actions,seqn) #[-1,:]\n",
    "                label = avar(torch.from_numpy(label).float())\n",
    "                loss += self._lossFunction(prediction, label, env=tenv)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % printEvery == 0: print(\" -> AvgLoss\",str(loss.data[0] / epochLen))\n",
    "            if epoch % validateEvery == 0:\n",
    "                bdata,blabels,bseqlen = validSeq.next(vbs,nopad=True)\n",
    "                acc1, _ = self._accuracyBatch(bdata,blabels,validSeq.env)\n",
    "                bdata,blabels,bseqlen = trainSeq.next(vbs,nopad=True)\n",
    "                acc2, _ = self._accuracyBatch(bdata,blabels,tenv)\n",
    "                print('\\tCurrent Training Acc (est) =', acc1)\n",
    "                print('\\tCurrent Validation Acc (est) =', acc2)\n",
    "    \n",
    "    def _lossFunction(self,outputs,targets,useMSE=True,env=None):\n",
    "        if useMSE:\n",
    "            loss = nn.MSELoss()\n",
    "            return loss(outputs,targets)\n",
    "        else: # Use Cross-entropy\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            cost = avar( torch.FloatTensor( [0] ) )\n",
    "            predVec = env.deconcatenateOneHotStateVector(outputs)\n",
    "            labelVec = env.deconcatenateOneHotStateVector(targets)\n",
    "            for pv,lv in zip(predVec,labelVec):\n",
    "                val,ind = lv.max(0)\n",
    "                cost += loss(pv.view(1,len(pv)), ind)\n",
    "            return cost / len(predVec)\n",
    "        \n",
    "    def _accuracyBatch(self,seqs,labels,env):\n",
    "        n, acc = float(len(seqs)), 0.0\n",
    "        #print(len(seq))\n",
    "        for s,l in zip(seqs,labels): acc += self._accuracySingle(s,l,env)\n",
    "        return acc / n, int(n)\n",
    "\n",
    "    # Accuracy averaged over subvecs\n",
    "    def _accuracySingle(self,seq,label,env):\n",
    "        seq = [avar(torch.from_numpy(s).float()) for s in seq] \n",
    "        seq = torch.cat(seq).view(len(seq), 1, -1) # [seqlen x batchlen x hidden_size]\n",
    "        self.reInitialize(1) # Reset LSTM hidden state\n",
    "        #print(seq.shape)\n",
    "        actions = [ s[0][64:74]  for s in seq ]\n",
    "        #actions = [ avar(torch.from_numpy(s).float()) for s in actions] \n",
    "        intial_state = seq[0][0][0:64].data.numpy()\n",
    "        seqn = len(seq)\n",
    "        prediction, _ = self.forward(intial_state,actions,seqn) #[-1,:]\n",
    "        #prediction = self.forward(seq) # Only retrieves final time state\n",
    "        predVec = env.deconcatenateOneHotStateVector(prediction)\n",
    "        labelVec = env.deconcatenateOneHotStateVector(label)\n",
    "        locAcc = 0.0\n",
    "        for pv, lv in zip(predVec, labelVec):\n",
    "            _, ind_pred = pv.max(0)\n",
    "            ind_label = np.argmax(lv)\n",
    "            locAcc += 1.0 if ind_pred.data[0] == ind_label else 0.0\n",
    "        return locAcc / len(predVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n"
     ]
    }
   ],
   "source": [
    "f_model_name = 'forward-lstm-stochastic.pt'    \n",
    "s = 'navigation' # 'transport'\n",
    "trainf, validf = s + \"-data-train-small.pickle\", s + \"-data-test-small.pickle\"\n",
    "print('Reading Data')\n",
    "train, valid = SeqData(trainf), SeqData(validf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 64\n"
     ]
    }
   ],
   "source": [
    "print(train.lenOfInput,train.lenOfState)\n",
    "fm = LSTMForwardModel(train.lenOfInput,train.lenOfState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 -> AvgLoss 0.07861821746826173\n",
      "\tCurrent Training Acc (est) = 0.1312000000000004\n",
      "\tCurrent Validation Acc (est) = 0.12640000000000046\n",
      "Epoch: 5 -> AvgLoss 0.06970014953613281\n",
      "Epoch: 10 -> AvgLoss 0.06739921569824218\n",
      "Epoch: 15 -> AvgLoss 0.06436611175537109\n",
      "Epoch: 20 -> AvgLoss 0.06016217041015625\n",
      "\tCurrent Training Acc (est) = 0.5628000000000002\n",
      "\tCurrent Validation Acc (est) = 0.5700000000000006\n",
      "Epoch: 25 -> AvgLoss 0.05613838195800781\n",
      "Epoch: 30 -> AvgLoss 0.052529346466064455\n",
      "Epoch: 35 -> AvgLoss 0.04765742111206055\n",
      "Epoch: 40 -> AvgLoss 0.044381328582763675\n",
      "\tCurrent Training Acc (est) = 0.7344000000000045\n",
      "\tCurrent Validation Acc (est) = 0.7216000000000043\n",
      "Epoch: 45 -> AvgLoss 0.04087410354614258\n",
      "Epoch: 50 -> AvgLoss 0.03824283599853515\n",
      "Epoch: 55 -> AvgLoss 0.03731814575195312\n",
      "Epoch: 60 -> AvgLoss 0.035043338775634765\n",
      "\tCurrent Training Acc (est) = 0.7604000000000053\n",
      "\tCurrent Validation Acc (est) = 0.7552000000000049\n",
      "Epoch: 65 -> AvgLoss 0.033585033416748046\n",
      "Epoch: 70 -> AvgLoss 0.03238039016723633\n",
      "Epoch: 75 -> AvgLoss 0.031388574600219724\n",
      "Epoch: 80 -> AvgLoss 0.03031843376159668\n",
      "\tCurrent Training Acc (est) = 0.7748000000000046\n",
      "\tCurrent Validation Acc (est) = 0.7788000000000043\n",
      "Epoch: 85 -> AvgLoss 0.030048515319824217\n",
      "Epoch: 90 -> AvgLoss 0.029124977111816407\n",
      "Epoch: 95 -> AvgLoss 0.028615644454956055\n",
      "Epoch: 100 -> AvgLoss 0.027882814407348633\n",
      "\tCurrent Training Acc (est) = 0.7884000000000047\n",
      "\tCurrent Validation Acc (est) = 0.7844000000000051\n",
      "Epoch: 105 -> AvgLoss 0.02725442314147949\n",
      "Epoch: 110 -> AvgLoss 0.027030763626098634\n",
      "Epoch: 115 -> AvgLoss 0.026825000762939453\n",
      "Epoch: 120 -> AvgLoss 0.02677811622619629\n",
      "\tCurrent Training Acc (est) = 0.8128000000000051\n",
      "\tCurrent Validation Acc (est) = 0.8100000000000048\n",
      "Epoch: 125 -> AvgLoss 0.026043970108032225\n",
      "Epoch: 130 -> AvgLoss 0.026012134552001954\n",
      "Epoch: 135 -> AvgLoss 0.0246610050201416\n",
      "Epoch: 140 -> AvgLoss 0.02454218673706055\n",
      "\tCurrent Training Acc (est) = 0.8272000000000047\n",
      "\tCurrent Validation Acc (est) = 0.8232000000000056\n",
      "Epoch: 145 -> AvgLoss 0.02403392219543457\n",
      "Epoch: 150 -> AvgLoss 0.02376709747314453\n",
      "Epoch: 155 -> AvgLoss 0.023924697875976564\n",
      "Epoch: 160 -> AvgLoss 0.02315603828430176\n",
      "\tCurrent Training Acc (est) = 0.8376000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8284000000000049\n",
      "Epoch: 165 -> AvgLoss 0.022572832107543947\n",
      "Epoch: 170 -> AvgLoss 0.022103633880615235\n",
      "Epoch: 175 -> AvgLoss 0.02177748489379883\n",
      "Epoch: 180 -> AvgLoss 0.02061915969848633\n",
      "\tCurrent Training Acc (est) = 0.8320000000000048\n",
      "\tCurrent Validation Acc (est) = 0.8448000000000049\n",
      "Epoch: 185 -> AvgLoss 0.0208570556640625\n",
      "Epoch: 190 -> AvgLoss 0.020238903045654295\n",
      "Epoch: 195 -> AvgLoss 0.020797407150268555\n",
      "Epoch: 200 -> AvgLoss 0.02015858268737793\n",
      "\tCurrent Training Acc (est) = 0.838800000000005\n",
      "\tCurrent Validation Acc (est) = 0.8520000000000048\n",
      "Epoch: 205 -> AvgLoss 0.01934976005554199\n",
      "Epoch: 210 -> AvgLoss 0.019436395645141602\n",
      "Epoch: 215 -> AvgLoss 0.018017051696777343\n",
      "Epoch: 220 -> AvgLoss 0.019001190185546874\n",
      "\tCurrent Training Acc (est) = 0.8464000000000047\n",
      "\tCurrent Validation Acc (est) = 0.8576000000000045\n",
      "Epoch: 225 -> AvgLoss 0.018157991409301757\n",
      "Epoch: 230 -> AvgLoss 0.018167781829833984\n",
      "Epoch: 235 -> AvgLoss 0.018616199493408203\n",
      "Epoch: 240 -> AvgLoss 0.018255857467651366\n",
      "\tCurrent Training Acc (est) = 0.8612000000000045\n",
      "\tCurrent Validation Acc (est) = 0.8444000000000045\n",
      "Epoch: 245 -> AvgLoss 0.017643604278564453\n",
      "Epoch: 250 -> AvgLoss 0.01721084976196289\n",
      "Epoch: 255 -> AvgLoss 0.017271293640136718\n",
      "Epoch: 260 -> AvgLoss 0.01741764259338379\n",
      "\tCurrent Training Acc (est) = 0.8568000000000044\n",
      "\tCurrent Validation Acc (est) = 0.8500000000000046\n",
      "Epoch: 265 -> AvgLoss 0.016941701889038086\n",
      "Epoch: 270 -> AvgLoss 0.016553205490112306\n",
      "Epoch: 275 -> AvgLoss 0.016524457931518556\n",
      "Epoch: 280 -> AvgLoss 0.01598805046081543\n",
      "\tCurrent Training Acc (est) = 0.8556000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8648000000000043\n",
      "Epoch: 285 -> AvgLoss 0.015507447242736816\n",
      "Epoch: 290 -> AvgLoss 0.015749212265014648\n",
      "Epoch: 295 -> AvgLoss 0.016460792541503906\n",
      "Epoch: 300 -> AvgLoss 0.01608924674987793\n",
      "\tCurrent Training Acc (est) = 0.8560000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8648000000000041\n",
      "Epoch: 305 -> AvgLoss 0.01516129970550537\n",
      "Epoch: 310 -> AvgLoss 0.01598828411102295\n",
      "Epoch: 315 -> AvgLoss 0.015513031959533692\n",
      "Epoch: 320 -> AvgLoss 0.015175884246826171\n",
      "\tCurrent Training Acc (est) = 0.8696000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8596000000000039\n",
      "Epoch: 325 -> AvgLoss 0.014793249130249023\n",
      "Epoch: 330 -> AvgLoss 0.015073473930358888\n",
      "Epoch: 335 -> AvgLoss 0.014848670959472655\n",
      "Epoch: 340 -> AvgLoss 0.014309510231018067\n",
      "\tCurrent Training Acc (est) = 0.8664000000000041\n",
      "\tCurrent Validation Acc (est) = 0.8544000000000046\n",
      "Epoch: 345 -> AvgLoss 0.01438653564453125\n",
      "Epoch: 350 -> AvgLoss 0.014696280479431152\n",
      "Epoch: 355 -> AvgLoss 0.01486854362487793\n",
      "Epoch: 360 -> AvgLoss 0.013864396095275879\n",
      "\tCurrent Training Acc (est) = 0.8704000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8640000000000044\n",
      "Epoch: 365 -> AvgLoss 0.01470923900604248\n",
      "Epoch: 370 -> AvgLoss 0.014774104118347169\n",
      "Epoch: 375 -> AvgLoss 0.014130970001220704\n",
      "Epoch: 380 -> AvgLoss 0.0140431547164917\n",
      "\tCurrent Training Acc (est) = 0.8656000000000044\n",
      "\tCurrent Validation Acc (est) = 0.8700000000000039\n",
      "Epoch: 385 -> AvgLoss 0.014417189598083496\n",
      "Epoch: 390 -> AvgLoss 0.014193282127380372\n",
      "Epoch: 395 -> AvgLoss 0.013801444053649902\n",
      "Epoch: 400 -> AvgLoss 0.0136151762008667\n",
      "\tCurrent Training Acc (est) = 0.8588000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8636000000000043\n",
      "Epoch: 405 -> AvgLoss 0.013818254470825195\n",
      "Epoch: 410 -> AvgLoss 0.014016724586486817\n",
      "Epoch: 415 -> AvgLoss 0.013737094879150391\n",
      "Epoch: 420 -> AvgLoss 0.014035505294799805\n",
      "\tCurrent Training Acc (est) = 0.8732000000000044\n",
      "\tCurrent Validation Acc (est) = 0.874000000000004\n",
      "Epoch: 425 -> AvgLoss 0.01275969886779785\n",
      "Epoch: 430 -> AvgLoss 0.01287182903289795\n",
      "Epoch: 435 -> AvgLoss 0.013261907577514649\n",
      "Epoch: 440 -> AvgLoss 0.012896359443664551\n",
      "\tCurrent Training Acc (est) = 0.877200000000004\n",
      "\tCurrent Validation Acc (est) = 0.8692000000000047\n",
      "Epoch: 445 -> AvgLoss 0.01360174560546875\n",
      "Epoch: 450 -> AvgLoss 0.0128443603515625\n",
      "Epoch: 455 -> AvgLoss 0.012391624450683593\n",
      "Epoch: 460 -> AvgLoss 0.013148946762084961\n",
      "\tCurrent Training Acc (est) = 0.8600000000000048\n",
      "\tCurrent Validation Acc (est) = 0.8708000000000042\n",
      "Epoch: 465 -> AvgLoss 0.012979180335998534\n",
      "Epoch: 470 -> AvgLoss 0.012492467880249023\n",
      "Epoch: 475 -> AvgLoss 0.012781418800354005\n",
      "Epoch: 480 -> AvgLoss 0.012600726127624511\n",
      "\tCurrent Training Acc (est) = 0.8648000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8592000000000044\n",
      "Epoch: 485 -> AvgLoss 0.013010378837585448\n",
      "Epoch: 490 -> AvgLoss 0.012526726722717286\n",
      "Epoch: 495 -> AvgLoss 0.012905596733093262\n",
      "Epoch: 500 -> AvgLoss 0.012963737487792969\n",
      "\tCurrent Training Acc (est) = 0.8760000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8696000000000041\n",
      "Epoch: 505 -> AvgLoss 0.01248135280609131\n",
      "Epoch: 510 -> AvgLoss 0.012695880889892578\n",
      "Epoch: 515 -> AvgLoss 0.012311771392822265\n",
      "Epoch: 520 -> AvgLoss 0.012403708457946777\n",
      "\tCurrent Training Acc (est) = 0.8748000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8796000000000038\n",
      "Epoch: 525 -> AvgLoss 0.011813854217529297\n",
      "Epoch: 530 -> AvgLoss 0.012505331993103027\n",
      "Epoch: 535 -> AvgLoss 0.011643866539001464\n",
      "Epoch: 540 -> AvgLoss 0.011642305374145508\n",
      "\tCurrent Training Acc (est) = 0.8800000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8808000000000038\n",
      "Epoch: 545 -> AvgLoss 0.011930200576782226\n",
      "Epoch: 550 -> AvgLoss 0.012349910736083984\n",
      "Epoch: 555 -> AvgLoss 0.012337292671203613\n",
      "Epoch: 560 -> AvgLoss 0.011916654586791992\n",
      "\tCurrent Training Acc (est) = 0.8808000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8884000000000035\n",
      "Epoch: 565 -> AvgLoss 0.011256248474121093\n",
      "Epoch: 570 -> AvgLoss 0.011455534934997558\n",
      "Epoch: 575 -> AvgLoss 0.011751923561096191\n",
      "Epoch: 580 -> AvgLoss 0.012143513679504395\n",
      "\tCurrent Training Acc (est) = 0.8800000000000037\n",
      "\tCurrent Validation Acc (est) = 0.8780000000000039\n",
      "Epoch: 585 -> AvgLoss 0.011763628005981446\n",
      "Epoch: 590 -> AvgLoss 0.011945677757263183\n",
      "Epoch: 595 -> AvgLoss 0.011805012702941894\n",
      "Epoch: 600 -> AvgLoss 0.011858062744140625\n",
      "\tCurrent Training Acc (est) = 0.8852000000000038\n",
      "\tCurrent Validation Acc (est) = 0.894000000000004\n",
      "Epoch: 605 -> AvgLoss 0.011905254364013672\n",
      "Epoch: 610 -> AvgLoss 0.012066761016845702\n",
      "Epoch: 615 -> AvgLoss 0.011557841300964355\n",
      "Epoch: 620 -> AvgLoss 0.011761806488037109\n",
      "\tCurrent Training Acc (est) = 0.8832000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8880000000000038\n",
      "Epoch: 625 -> AvgLoss 0.011554119110107421\n",
      "Epoch: 630 -> AvgLoss 0.011614452362060547\n",
      "Epoch: 635 -> AvgLoss 0.012077946662902832\n",
      "Epoch: 640 -> AvgLoss 0.01154330062866211\n",
      "\tCurrent Training Acc (est) = 0.8812000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8876000000000034\n",
      "Epoch: 645 -> AvgLoss 0.01156209659576416\n",
      "Epoch: 650 -> AvgLoss 0.011271270751953125\n",
      "Epoch: 655 -> AvgLoss 0.011591156959533692\n",
      "Epoch: 660 -> AvgLoss 0.010500556945800781\n",
      "\tCurrent Training Acc (est) = 0.8864000000000037\n",
      "\tCurrent Validation Acc (est) = 0.890000000000004\n",
      "Epoch: 665 -> AvgLoss 0.011408757209777833\n",
      "Epoch: 670 -> AvgLoss 0.01086605167388916\n",
      "Epoch: 675 -> AvgLoss 0.011667886734008788\n",
      "Epoch: 680 -> AvgLoss 0.011509364128112792\n",
      "\tCurrent Training Acc (est) = 0.8892000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8892000000000034\n",
      "Epoch: 685 -> AvgLoss 0.011313080787658691\n",
      "Epoch: 690 -> AvgLoss 0.011547110557556152\n",
      "Epoch: 695 -> AvgLoss 0.011505182266235352\n",
      "Epoch: 700 -> AvgLoss 0.011317084312438965\n",
      "\tCurrent Training Acc (est) = 0.8932000000000034\n",
      "\tCurrent Validation Acc (est) = 0.8876000000000037\n",
      "Epoch: 705 -> AvgLoss 0.010631382942199707\n",
      "Epoch: 710 -> AvgLoss 0.011178239822387696\n",
      "Epoch: 715 -> AvgLoss 0.010823036193847656\n",
      "Epoch: 720 -> AvgLoss 0.011217938423156739\n",
      "\tCurrent Training Acc (est) = 0.8988000000000037\n",
      "\tCurrent Validation Acc (est) = 0.8896000000000035\n",
      "Epoch: 725 -> AvgLoss 0.01125745964050293\n",
      "Epoch: 730 -> AvgLoss 0.010768446922302246\n",
      "Epoch: 735 -> AvgLoss 0.010842841148376465\n",
      "Epoch: 740 -> AvgLoss 0.010070292472839356\n",
      "\tCurrent Training Acc (est) = 0.8852000000000032\n",
      "\tCurrent Validation Acc (est) = 0.8916000000000041\n",
      "Epoch: 745 -> AvgLoss 0.010509492874145508\n",
      "Epoch: 750 -> AvgLoss 0.010179027557373047\n",
      "Epoch: 755 -> AvgLoss 0.01070787239074707\n",
      "Epoch: 760 -> AvgLoss 0.010472872734069823\n",
      "\tCurrent Training Acc (est) = 0.8904000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8928000000000036\n",
      "Epoch: 765 -> AvgLoss 0.010511410713195802\n",
      "Epoch: 770 -> AvgLoss 0.010587369918823242\n",
      "Epoch: 775 -> AvgLoss 0.010204485893249512\n",
      "Epoch: 780 -> AvgLoss 0.010671135902404785\n",
      "\tCurrent Training Acc (est) = 0.8932000000000038\n",
      "\tCurrent Validation Acc (est) = 0.9136000000000029\n",
      "Epoch: 785 -> AvgLoss 0.011222704887390137\n",
      "Epoch: 790 -> AvgLoss 0.0108305082321167\n",
      "Epoch: 795 -> AvgLoss 0.010336481094360351\n",
      "Epoch: 800 -> AvgLoss 0.011037230491638184\n",
      "\tCurrent Training Acc (est) = 0.9004000000000034\n",
      "\tCurrent Validation Acc (est) = 0.8968000000000036\n",
      "Epoch: 805 -> AvgLoss 0.010706310272216796\n",
      "Epoch: 810 -> AvgLoss 0.010670183181762695\n",
      "Epoch: 815 -> AvgLoss 0.010975753784179688\n",
      "Epoch: 820 -> AvgLoss 0.010875597953796386\n",
      "\tCurrent Training Acc (est) = 0.8964000000000033\n",
      "\tCurrent Validation Acc (est) = 0.9024000000000031\n",
      "Epoch: 825 -> AvgLoss 0.010035035133361816\n",
      "Epoch: 830 -> AvgLoss 0.010546543121337891\n",
      "Epoch: 835 -> AvgLoss 0.010133166313171387\n",
      "Epoch: 840 -> AvgLoss 0.009665823936462403\n",
      "\tCurrent Training Acc (est) = 0.9008000000000028\n",
      "\tCurrent Validation Acc (est) = 0.8996000000000037\n",
      "Epoch: 845 -> AvgLoss 0.010345595359802246\n",
      "Epoch: 850 -> AvgLoss 0.010403580665588379\n",
      "Epoch: 855 -> AvgLoss 0.010778639793395996\n",
      "Epoch: 860 -> AvgLoss 0.009945005416870116\n",
      "\tCurrent Training Acc (est) = 0.9072000000000032\n",
      "\tCurrent Validation Acc (est) = 0.9036000000000033\n",
      "Epoch: 865 -> AvgLoss 0.00992827033996582\n",
      "Epoch: 870 -> AvgLoss 0.01043840217590332\n",
      "Epoch: 875 -> AvgLoss 0.010235736846923828\n",
      "Epoch: 880 -> AvgLoss 0.010353626251220703\n",
      "\tCurrent Training Acc (est) = 0.8984000000000035\n",
      "\tCurrent Validation Acc (est) = 0.8936000000000035\n",
      "Epoch: 885 -> AvgLoss 0.010231451988220215\n",
      "Epoch: 890 -> AvgLoss 0.010053799629211426\n",
      "Epoch: 895 -> AvgLoss 0.009961440086364745\n",
      "Epoch: 900 -> AvgLoss 0.009875349998474121\n",
      "\tCurrent Training Acc (est) = 0.912000000000003\n",
      "\tCurrent Validation Acc (est) = 0.9064000000000034\n",
      "Epoch: 905 -> AvgLoss 0.009869820594787597\n",
      "Epoch: 910 -> AvgLoss 0.010340797424316405\n",
      "Epoch: 915 -> AvgLoss 0.009940227508544923\n",
      "Epoch: 920 -> AvgLoss 0.009724368095397949\n",
      "\tCurrent Training Acc (est) = 0.919200000000003\n",
      "\tCurrent Validation Acc (est) = 0.9124000000000028\n",
      "Epoch: 925 -> AvgLoss 0.010121515274047851\n",
      "Epoch: 930 -> AvgLoss 0.009755487442016602\n",
      "Epoch: 935 -> AvgLoss 0.009488663673400878\n",
      "Epoch: 940 -> AvgLoss 0.009531453132629394\n",
      "\tCurrent Training Acc (est) = 0.9188000000000031\n",
      "\tCurrent Validation Acc (est) = 0.9164000000000028\n",
      "Epoch: 945 -> AvgLoss 0.00953548240661621\n",
      "Epoch: 950 -> AvgLoss 0.009614696502685547\n",
      "Epoch: 955 -> AvgLoss 0.01023717975616455\n",
      "Epoch: 960 -> AvgLoss 0.009537870407104493\n",
      "\tCurrent Training Acc (est) = 0.9164000000000027\n",
      "\tCurrent Validation Acc (est) = 0.9188000000000027\n",
      "Epoch: 965 -> AvgLoss 0.010212665557861328\n",
      "Epoch: 970 -> AvgLoss 0.009305261611938476\n",
      "Epoch: 975 -> AvgLoss 0.010118106842041015\n",
      "Epoch: 980 -> AvgLoss 0.00960075569152832\n",
      "\tCurrent Training Acc (est) = 0.912400000000003\n",
      "\tCurrent Validation Acc (est) = 0.9144000000000031\n",
      "Epoch: 985 -> AvgLoss 0.009726962089538575\n",
      "Epoch: 990 -> AvgLoss 0.00937123203277588\n",
      "Epoch: 995 -> AvgLoss 0.009733463287353515\n",
      "Epoch: 1000 -> AvgLoss 0.009511466026306153\n",
      "\tCurrent Training Acc (est) = 0.916800000000003\n",
      "\tCurrent Validation Acc (est) = 0.9236000000000029\n",
      "Epoch: 1005 -> AvgLoss 0.009278081893920898\n",
      "Epoch: 1010 -> AvgLoss 0.009242777824401855\n",
      "Epoch: 1015 -> AvgLoss 0.009555838584899902\n",
      "Epoch: 1020 -> AvgLoss 0.009264739990234375\n",
      "\tCurrent Training Acc (est) = 0.9176000000000033\n",
      "\tCurrent Validation Acc (est) = 0.9136000000000029\n",
      "Epoch: 1025 -> AvgLoss 0.009160392761230469\n",
      "Epoch: 1030 -> AvgLoss 0.009463425636291503\n",
      "Epoch: 1035 -> AvgLoss 0.00952820873260498\n",
      "Epoch: 1040 -> AvgLoss 0.00889427089691162\n",
      "\tCurrent Training Acc (est) = 0.9304000000000027\n",
      "\tCurrent Validation Acc (est) = 0.917200000000003\n",
      "Epoch: 1045 -> AvgLoss 0.00902729320526123\n",
      "Epoch: 1050 -> AvgLoss 0.009523969650268554\n",
      "Epoch: 1055 -> AvgLoss 0.009248945236206054\n",
      "Epoch: 1060 -> AvgLoss 0.00911562442779541\n",
      "\tCurrent Training Acc (est) = 0.9216000000000026\n",
      "\tCurrent Validation Acc (est) = 0.9244000000000026\n",
      "Epoch: 1065 -> AvgLoss 0.00897305965423584\n",
      "Epoch: 1070 -> AvgLoss 0.009365788459777832\n",
      "Epoch: 1075 -> AvgLoss 0.00973508071899414\n",
      "Epoch: 1080 -> AvgLoss 0.008912642478942872\n",
      "\tCurrent Training Acc (est) = 0.9236000000000026\n",
      "\tCurrent Validation Acc (est) = 0.9272000000000027\n",
      "Epoch: 1085 -> AvgLoss 0.008939135551452636\n",
      "Epoch: 1090 -> AvgLoss 0.008565347671508789\n",
      "Epoch: 1095 -> AvgLoss 0.00884888458251953\n",
      "Epoch: 1100 -> AvgLoss 0.009094839096069335\n",
      "\tCurrent Training Acc (est) = 0.928800000000002\n",
      "\tCurrent Validation Acc (est) = 0.9236000000000028\n",
      "Epoch: 1105 -> AvgLoss 0.008829004287719726\n",
      "Epoch: 1110 -> AvgLoss 0.009154412269592285\n",
      "Epoch: 1115 -> AvgLoss 0.008827890396118164\n",
      "Epoch: 1120 -> AvgLoss 0.009379478454589843\n",
      "\tCurrent Training Acc (est) = 0.9300000000000027\n",
      "\tCurrent Validation Acc (est) = 0.9288000000000027\n",
      "Epoch: 1125 -> AvgLoss 0.008570091247558594\n",
      "Epoch: 1130 -> AvgLoss 0.009222991943359375\n",
      "Epoch: 1135 -> AvgLoss 0.009109386444091797\n",
      "Epoch: 1140 -> AvgLoss 0.008596904754638672\n",
      "\tCurrent Training Acc (est) = 0.9336000000000025\n",
      "\tCurrent Validation Acc (est) = 0.9376000000000022\n",
      "Epoch: 1145 -> AvgLoss 0.00875083065032959\n",
      "Epoch: 1150 -> AvgLoss 0.008593018531799317\n",
      "Epoch: 1155 -> AvgLoss 0.009016260147094727\n",
      "Epoch: 1160 -> AvgLoss 0.00911100959777832\n",
      "\tCurrent Training Acc (est) = 0.9380000000000023\n",
      "\tCurrent Validation Acc (est) = 0.9288000000000027\n",
      "Epoch: 1165 -> AvgLoss 0.009370351791381836\n",
      "Epoch: 1170 -> AvgLoss 0.008976236343383789\n",
      "Epoch: 1175 -> AvgLoss 0.008957984924316407\n",
      "Epoch: 1180 -> AvgLoss 0.008226035118103027\n",
      "\tCurrent Training Acc (est) = 0.9212000000000031\n",
      "\tCurrent Validation Acc (est) = 0.9372000000000021\n",
      "Epoch: 1185 -> AvgLoss 0.008720944404602051\n",
      "Epoch: 1190 -> AvgLoss 0.008794133186340331\n",
      "Epoch: 1195 -> AvgLoss 0.00872822093963623\n",
      "Epoch: 1200 -> AvgLoss 0.008647579193115235\n",
      "\tCurrent Training Acc (est) = 0.9260000000000027\n",
      "\tCurrent Validation Acc (est) = 0.9304000000000026\n",
      "Epoch: 1205 -> AvgLoss 0.008671844482421875\n",
      "Epoch: 1210 -> AvgLoss 0.007939385890960693\n",
      "Epoch: 1215 -> AvgLoss 0.008748628616333009\n",
      "Epoch: 1220 -> AvgLoss 0.008368642807006835\n",
      "\tCurrent Training Acc (est) = 0.9356000000000024\n",
      "\tCurrent Validation Acc (est) = 0.9380000000000026\n",
      "Epoch: 1225 -> AvgLoss 0.007638996601104737\n",
      "Epoch: 1230 -> AvgLoss 0.008343351364135743\n",
      "Epoch: 1235 -> AvgLoss 0.008492815017700195\n",
      "Epoch: 1240 -> AvgLoss 0.008542618751525878\n",
      "\tCurrent Training Acc (est) = 0.9352000000000023\n",
      "\tCurrent Validation Acc (est) = 0.9344000000000021\n",
      "Epoch: 1245 -> AvgLoss 0.007993193626403808\n",
      "Epoch: 1250 -> AvgLoss 0.007853655815124512\n",
      "Epoch: 1255 -> AvgLoss 0.008599187850952148\n",
      "Epoch: 1260 -> AvgLoss 0.00849421215057373\n",
      "\tCurrent Training Acc (est) = 0.9440000000000021\n",
      "\tCurrent Validation Acc (est) = 0.9408000000000021\n",
      "Epoch: 1265 -> AvgLoss 0.008499211311340332\n",
      "Epoch: 1270 -> AvgLoss 0.007855469226837159\n",
      "Epoch: 1275 -> AvgLoss 0.008344742774963379\n",
      "Epoch: 1280 -> AvgLoss 0.007697017192840576\n",
      "\tCurrent Training Acc (est) = 0.9432000000000025\n",
      "\tCurrent Validation Acc (est) = 0.9452000000000023\n",
      "Epoch: 1285 -> AvgLoss 0.0077027082443237305\n",
      "Epoch: 1290 -> AvgLoss 0.008126108169555665\n",
      "Epoch: 1295 -> AvgLoss 0.008144743919372558\n",
      "Epoch: 1300 -> AvgLoss 0.007494946479797363\n",
      "\tCurrent Training Acc (est) = 0.9464000000000021\n",
      "\tCurrent Validation Acc (est) = 0.9460000000000018\n",
      "Epoch: 1305 -> AvgLoss 0.008034008979797364\n",
      "Epoch: 1310 -> AvgLoss 0.008116481781005859\n",
      "Epoch: 1315 -> AvgLoss 0.007292543411254883\n",
      "Epoch: 1320 -> AvgLoss 0.007701932907104492\n",
      "\tCurrent Training Acc (est) = 0.9440000000000023\n",
      "\tCurrent Validation Acc (est) = 0.9480000000000018\n",
      "Epoch: 1325 -> AvgLoss 0.008074346542358399\n",
      "Epoch: 1330 -> AvgLoss 0.0076104850769042965\n",
      "Epoch: 1335 -> AvgLoss 0.0072957749366760255\n",
      "Epoch: 1340 -> AvgLoss 0.0071545419692993165\n",
      "\tCurrent Training Acc (est) = 0.9600000000000016\n",
      "\tCurrent Validation Acc (est) = 0.9664000000000013\n",
      "Epoch: 1345 -> AvgLoss 0.00717380428314209\n",
      "Epoch: 1350 -> AvgLoss 0.007442298889160156\n",
      "Epoch: 1355 -> AvgLoss 0.0071867995262145995\n",
      "Epoch: 1360 -> AvgLoss 0.007186593532562256\n",
      "\tCurrent Training Acc (est) = 0.9564000000000016\n",
      "\tCurrent Validation Acc (est) = 0.9592000000000014\n",
      "Epoch: 1365 -> AvgLoss 0.00723845386505127\n",
      "Epoch: 1370 -> AvgLoss 0.006685076713562011\n",
      "Epoch: 1375 -> AvgLoss 0.006794512748718262\n",
      "Epoch: 1380 -> AvgLoss 0.006919064521789551\n",
      "\tCurrent Training Acc (est) = 0.9668000000000011\n",
      "\tCurrent Validation Acc (est) = 0.9604000000000015\n",
      "Epoch: 1385 -> AvgLoss 0.006852127075195312\n",
      "Epoch: 1390 -> AvgLoss 0.007046451091766357\n",
      "Epoch: 1395 -> AvgLoss 0.006499791622161865\n",
      "Epoch: 1400 -> AvgLoss 0.006512377738952637\n",
      "\tCurrent Training Acc (est) = 0.9712000000000011\n",
      "\tCurrent Validation Acc (est) = 0.9604000000000015\n",
      "Epoch: 1405 -> AvgLoss 0.006855813026428223\n",
      "Epoch: 1410 -> AvgLoss 0.006044411182403565\n",
      "Epoch: 1415 -> AvgLoss 0.006419716835021972\n",
      "Epoch: 1420 -> AvgLoss 0.00660758113861084\n",
      "\tCurrent Training Acc (est) = 0.9688000000000013\n",
      "\tCurrent Validation Acc (est) = 0.9660000000000015\n",
      "Epoch: 1425 -> AvgLoss 0.006295403480529785\n",
      "Epoch: 1430 -> AvgLoss 0.00650615930557251\n",
      "Epoch: 1435 -> AvgLoss 0.006251695156097412\n",
      "Epoch: 1440 -> AvgLoss 0.006118171215057373\n",
      "\tCurrent Training Acc (est) = 0.9792000000000007\n",
      "\tCurrent Validation Acc (est) = 0.9728000000000012\n",
      "Epoch: 1445 -> AvgLoss 0.0061821889877319335\n",
      "Epoch: 1450 -> AvgLoss 0.006140078544616699\n",
      "Epoch: 1455 -> AvgLoss 0.005784532070159912\n",
      "Epoch: 1460 -> AvgLoss 0.00625669002532959\n",
      "\tCurrent Training Acc (est) = 0.9792000000000007\n",
      "\tCurrent Validation Acc (est) = 0.9780000000000009\n",
      "Epoch: 1465 -> AvgLoss 0.0062627320289611816\n",
      "Epoch: 1470 -> AvgLoss 0.005715366840362549\n",
      "Epoch: 1475 -> AvgLoss 0.005361933708190918\n",
      "Epoch: 1480 -> AvgLoss 0.005831379413604737\n",
      "\tCurrent Training Acc (est) = 0.9840000000000008\n",
      "\tCurrent Validation Acc (est) = 0.9812000000000006\n",
      "Epoch: 1485 -> AvgLoss 0.0058005437850952146\n",
      "Epoch: 1490 -> AvgLoss 0.005407792568206787\n",
      "Epoch: 1495 -> AvgLoss 0.005094915390014648\n"
     ]
    }
   ],
   "source": [
    "fm.train(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(fm.state_dict(), \"LSTM_FM_1_98\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 -> AvgLoss 0.013008377075195313\n",
      "\tCurrent Training Acc (est) = 0.8744000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8700000000000041\n",
      "Epoch: 5 -> AvgLoss 0.015376659393310546\n",
      "\tCurrent Training Acc (est) = 0.8656000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8692000000000047\n",
      "Epoch: 10 -> AvgLoss 0.014667679786682129\n",
      "\tCurrent Training Acc (est) = 0.8656000000000045\n",
      "\tCurrent Validation Acc (est) = 0.8852000000000039\n",
      "Epoch: 15 -> AvgLoss 0.013238248825073242\n",
      "\tCurrent Training Acc (est) = 0.8612000000000047\n",
      "\tCurrent Validation Acc (est) = 0.8828000000000039\n",
      "Epoch: 20 -> AvgLoss 0.013871088981628418\n",
      "\tCurrent Training Acc (est) = 0.8688000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8716000000000038\n",
      "Epoch: 25 -> AvgLoss 0.012729496002197265\n",
      "\tCurrent Training Acc (est) = 0.8676000000000045\n",
      "\tCurrent Validation Acc (est) = 0.8776000000000037\n",
      "Epoch: 30 -> AvgLoss 0.013888617515563965\n",
      "\tCurrent Training Acc (est) = 0.8692000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8768000000000038\n",
      "Epoch: 35 -> AvgLoss 0.01374160385131836\n",
      "\tCurrent Training Acc (est) = 0.8720000000000038\n",
      "\tCurrent Validation Acc (est) = 0.875200000000004\n",
      "Epoch: 40 -> AvgLoss 0.013432912826538086\n",
      "\tCurrent Training Acc (est) = 0.871200000000004\n",
      "\tCurrent Validation Acc (est) = 0.860800000000005\n",
      "Epoch: 45 -> AvgLoss 0.012043789863586426\n",
      "\tCurrent Training Acc (est) = 0.8656000000000041\n",
      "\tCurrent Validation Acc (est) = 0.875200000000004\n",
      "Epoch: 50 -> AvgLoss 0.012942350387573243\n",
      "\tCurrent Training Acc (est) = 0.8616000000000046\n",
      "\tCurrent Validation Acc (est) = 0.8820000000000038\n",
      "Epoch: 55 -> AvgLoss 0.01271566867828369\n",
      "\tCurrent Training Acc (est) = 0.8804000000000037\n",
      "\tCurrent Validation Acc (est) = 0.8812000000000036\n",
      "Epoch: 60 -> AvgLoss 0.013357178688049316\n",
      "\tCurrent Training Acc (est) = 0.8692000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8828000000000039\n",
      "Epoch: 65 -> AvgLoss 0.013074932098388671\n",
      "\tCurrent Training Acc (est) = 0.8668000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8760000000000041\n",
      "Epoch: 70 -> AvgLoss 0.012098911285400391\n",
      "\tCurrent Training Acc (est) = 0.875600000000004\n",
      "\tCurrent Validation Acc (est) = 0.869200000000004\n",
      "Epoch: 75 -> AvgLoss 0.012831310272216796\n",
      "\tCurrent Training Acc (est) = 0.8780000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8724000000000042\n",
      "Epoch: 80 -> AvgLoss 0.012380203247070313\n",
      "\tCurrent Training Acc (est) = 0.8660000000000043\n",
      "\tCurrent Validation Acc (est) = 0.884000000000004\n",
      "Epoch: 85 -> AvgLoss 0.012889845848083496\n",
      "\tCurrent Training Acc (est) = 0.8732000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8728000000000038\n",
      "Epoch: 90 -> AvgLoss 0.01145923137664795\n",
      "\tCurrent Training Acc (est) = 0.8628000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8860000000000035\n",
      "Epoch: 95 -> AvgLoss 0.012507633209228515\n",
      "\tCurrent Training Acc (est) = 0.8720000000000041\n",
      "\tCurrent Validation Acc (est) = 0.8844000000000033\n",
      "Epoch: 100 -> AvgLoss 0.013321240425109864\n",
      "\tCurrent Training Acc (est) = 0.8788000000000041\n",
      "\tCurrent Validation Acc (est) = 0.8848000000000035\n",
      "Epoch: 105 -> AvgLoss 0.013309014320373536\n",
      "\tCurrent Training Acc (est) = 0.8780000000000041\n",
      "\tCurrent Validation Acc (est) = 0.8900000000000036\n",
      "Epoch: 110 -> AvgLoss 0.012473977088928223\n",
      "\tCurrent Training Acc (est) = 0.8668000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8872000000000035\n",
      "Epoch: 115 -> AvgLoss 0.012265238761901855\n",
      "\tCurrent Training Acc (est) = 0.8660000000000041\n",
      "\tCurrent Validation Acc (est) = 0.8748000000000038\n",
      "Epoch: 120 -> AvgLoss 0.013772772789001466\n",
      "\tCurrent Training Acc (est) = 0.8752000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8796000000000038\n",
      "Epoch: 125 -> AvgLoss 0.01211113452911377\n",
      "\tCurrent Training Acc (est) = 0.8724000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8764000000000042\n",
      "Epoch: 130 -> AvgLoss 0.011728797912597656\n",
      "\tCurrent Training Acc (est) = 0.8808000000000037\n",
      "\tCurrent Validation Acc (est) = 0.8780000000000039\n",
      "Epoch: 135 -> AvgLoss 0.012290745735168458\n",
      "\tCurrent Training Acc (est) = 0.8688000000000045\n",
      "\tCurrent Validation Acc (est) = 0.8844000000000038\n",
      "Epoch: 140 -> AvgLoss 0.011587918281555176\n",
      "\tCurrent Training Acc (est) = 0.8760000000000039\n",
      "\tCurrent Validation Acc (est) = 0.876000000000004\n",
      "Epoch: 145 -> AvgLoss 0.012880584716796876\n",
      "\tCurrent Training Acc (est) = 0.8676000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8780000000000038\n",
      "Epoch: 150 -> AvgLoss 0.012264042854309083\n",
      "\tCurrent Training Acc (est) = 0.8768000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8744000000000041\n",
      "Epoch: 155 -> AvgLoss 0.013194058418273926\n",
      "\tCurrent Training Acc (est) = 0.8772000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8772000000000035\n",
      "Epoch: 160 -> AvgLoss 0.012415369987487794\n",
      "\tCurrent Training Acc (est) = 0.8756000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8932000000000034\n",
      "Epoch: 165 -> AvgLoss 0.01199772071838379\n",
      "\tCurrent Training Acc (est) = 0.8704000000000035\n",
      "\tCurrent Validation Acc (est) = 0.8784000000000038\n",
      "Epoch: 170 -> AvgLoss 0.012469598770141602\n",
      "\tCurrent Training Acc (est) = 0.8724000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8856000000000035\n",
      "Epoch: 175 -> AvgLoss 0.012580020904541016\n",
      "\tCurrent Training Acc (est) = 0.8816000000000035\n",
      "\tCurrent Validation Acc (est) = 0.8792000000000041\n",
      "Epoch: 180 -> AvgLoss 0.012481330871582031\n",
      "\tCurrent Training Acc (est) = 0.8788000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8804000000000041\n",
      "Epoch: 185 -> AvgLoss 0.012800975799560547\n",
      "\tCurrent Training Acc (est) = 0.8820000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8808000000000036\n",
      "Epoch: 190 -> AvgLoss 0.012608046531677247\n",
      "\tCurrent Training Acc (est) = 0.8632000000000044\n",
      "\tCurrent Validation Acc (est) = 0.884400000000004\n",
      "Epoch: 195 -> AvgLoss 0.012692535400390625\n",
      "\tCurrent Training Acc (est) = 0.8704000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8764000000000043\n",
      "Epoch: 200 -> AvgLoss 0.012287558555603028\n",
      "\tCurrent Training Acc (est) = 0.8720000000000043\n",
      "\tCurrent Validation Acc (est) = 0.8776000000000036\n",
      "Epoch: 205 -> AvgLoss 0.012978363037109374\n",
      "\tCurrent Training Acc (est) = 0.868800000000004\n",
      "\tCurrent Validation Acc (est) = 0.8840000000000037\n",
      "Epoch: 210 -> AvgLoss 0.01265546703338623\n",
      "\tCurrent Training Acc (est) = 0.8788000000000036\n",
      "\tCurrent Validation Acc (est) = 0.8864000000000037\n",
      "Epoch: 215 -> AvgLoss 0.012083028793334961\n",
      "\tCurrent Training Acc (est) = 0.873600000000004\n",
      "\tCurrent Validation Acc (est) = 0.8820000000000039\n",
      "Epoch: 220 -> AvgLoss 0.012742547035217286\n",
      "\tCurrent Training Acc (est) = 0.8680000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8892000000000035\n",
      "Epoch: 225 -> AvgLoss 0.011813196182250976\n",
      "\tCurrent Training Acc (est) = 0.8780000000000041\n",
      "\tCurrent Validation Acc (est) = 0.877600000000004\n",
      "Epoch: 230 -> AvgLoss 0.012850017547607421\n",
      "\tCurrent Training Acc (est) = 0.8784000000000038\n",
      "\tCurrent Validation Acc (est) = 0.881600000000004\n",
      "Epoch: 235 -> AvgLoss 0.012540949821472167\n",
      "\tCurrent Training Acc (est) = 0.8820000000000041\n",
      "\tCurrent Validation Acc (est) = 0.8848000000000038\n",
      "Epoch: 240 -> AvgLoss 0.01228056526184082\n",
      "\tCurrent Training Acc (est) = 0.8700000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8876000000000033\n",
      "Epoch: 245 -> AvgLoss 0.013027800559997558\n",
      "\tCurrent Training Acc (est) = 0.8816000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8772000000000036\n",
      "Epoch: 250 -> AvgLoss 0.012090749740600586\n",
      "\tCurrent Training Acc (est) = 0.8716000000000044\n",
      "\tCurrent Validation Acc (est) = 0.8884000000000036\n",
      "Epoch: 255 -> AvgLoss 0.012543042182922364\n",
      "\tCurrent Training Acc (est) = 0.8788000000000042\n",
      "\tCurrent Validation Acc (est) = 0.886000000000004\n",
      "Epoch: 260 -> AvgLoss 0.012326948165893555\n",
      "\tCurrent Training Acc (est) = 0.883600000000004\n",
      "\tCurrent Validation Acc (est) = 0.8892000000000037\n",
      "Epoch: 265 -> AvgLoss 0.012765522956848144\n",
      "\tCurrent Training Acc (est) = 0.880400000000004\n",
      "\tCurrent Validation Acc (est) = 0.882000000000004\n",
      "Epoch: 270 -> AvgLoss 0.01202173137664795\n",
      "\tCurrent Training Acc (est) = 0.8724000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8808000000000039\n",
      "Epoch: 275 -> AvgLoss 0.012354362487792968\n",
      "\tCurrent Training Acc (est) = 0.8816000000000037\n",
      "\tCurrent Validation Acc (est) = 0.8856000000000042\n",
      "Epoch: 280 -> AvgLoss 0.012505716323852539\n",
      "\tCurrent Training Acc (est) = 0.8828000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8856000000000034\n",
      "Epoch: 285 -> AvgLoss 0.012307937622070313\n",
      "\tCurrent Training Acc (est) = 0.8804000000000038\n",
      "\tCurrent Validation Acc (est) = 0.8824000000000035\n",
      "Epoch: 290 -> AvgLoss 0.011848825454711914\n",
      "\tCurrent Training Acc (est) = 0.882400000000004\n",
      "\tCurrent Validation Acc (est) = 0.8892000000000037\n",
      "Epoch: 295 -> AvgLoss 0.011792118072509766\n",
      "\tCurrent Training Acc (est) = 0.8816000000000037\n",
      "\tCurrent Validation Acc (est) = 0.8828000000000039\n",
      "Epoch: 300 -> AvgLoss 0.011854523658752442\n",
      "\tCurrent Training Acc (est) = 0.883600000000004\n",
      "\tCurrent Validation Acc (est) = 0.8760000000000039\n",
      "Epoch: 305 -> AvgLoss 0.011519085884094239\n",
      "\tCurrent Training Acc (est) = 0.8788000000000039\n",
      "\tCurrent Validation Acc (est) = 0.885600000000004\n",
      "Epoch: 310 -> AvgLoss 0.012330561637878419\n",
      "\tCurrent Training Acc (est) = 0.8740000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8888000000000039\n",
      "Epoch: 315 -> AvgLoss 0.012545440673828125\n",
      "\tCurrent Training Acc (est) = 0.8852000000000035\n",
      "\tCurrent Validation Acc (est) = 0.8928000000000035\n",
      "Epoch: 320 -> AvgLoss 0.011830157279968261\n",
      "\tCurrent Training Acc (est) = 0.8780000000000039\n",
      "\tCurrent Validation Acc (est) = 0.8860000000000036\n",
      "Epoch: 325 -> AvgLoss 0.011067172050476075\n",
      "\tCurrent Training Acc (est) = 0.8760000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8764000000000035\n",
      "Epoch: 330 -> AvgLoss 0.012848243713378907\n",
      "\tCurrent Training Acc (est) = 0.8796000000000042\n",
      "\tCurrent Validation Acc (est) = 0.8936000000000035\n",
      "Epoch: 335 -> AvgLoss 0.012305288314819337\n"
     ]
    }
   ],
   "source": [
    "fm.train(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(fm.state_dict(), \"LSTM_FM_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "actions = []\n",
    "for j in range(10):\n",
    "    action = np.zeros( 10 )\n",
    "    action[ npr.randint(0,10) ] = 1\n",
    "    actions.append(action)\n",
    "actions = np.asarray(actions)\n",
    "actions = avar(torch.from_numpy(actions).float())\n",
    "exampleEnv = NavigationTask()\n",
    "inital_state = exampleEnv.getStateRep()\n",
    "print(inital_state)\n",
    "final_State , intermediate_state = fm.forward(inital_state, actions, 5)\n",
    "final_State = final_State.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1875875e-02  2.4601117e-02 -6.5202452e-03  7.3336400e-02\n",
      "  1.2798220e-01  2.9160172e-01  3.1932461e-01  9.8608591e-02\n",
      "  8.2296304e-02 -1.8412858e-02  1.0076821e-02  1.8662903e-03\n",
      "  2.0893149e-02  5.4644514e-02 -2.2633627e-02  2.6738644e-02\n",
      " -5.6180120e-02 -2.0300578e-01  4.0981669e-02 -8.6036421e-02\n",
      "  3.3219814e-01  6.2109228e-02  6.7701274e-01  6.2240537e-02\n",
      "  1.1215083e-01 -1.8102080e-01  1.3881046e-01 -5.7481341e-02\n",
      "  1.7736137e-01 -5.5281729e-02  1.6142691e-02 -1.1346847e-02\n",
      "  1.0079575e+00  2.3069939e-02  3.3039648e-02  6.9703013e-02\n",
      "  2.2586552e-02 -9.4303362e-02 -6.1772116e-02 -6.6349972e-03\n",
      "  7.4274100e-02  6.8789423e-02  7.8592002e-03  7.3187649e-03\n",
      " -8.0595128e-03  6.5140426e-03  3.3716675e-02 -4.4507261e-02\n",
      "  9.1718858e-01  3.7553817e-02  1.0577283e-01 -1.3109421e-02\n",
      "  1.1834033e-02 -5.2856430e-03  2.7422644e-03 -4.4638518e-02\n",
      "  5.2091077e-02 -9.4498619e-02 -7.2856620e-03 -3.7650973e-02\n",
      " -2.8304383e-04  8.1735373e-02 -7.2692037e-02  1.0059174e+00]\n",
      "6\n",
      "7\n",
      "2\n",
      "14\n",
      "14\n",
      "[ 0.  0.  0.  0.  1.  0. 14. 14.]\n"
     ]
    }
   ],
   "source": [
    "print(final_State)\n",
    "print(final_State[0:15].argmax())\n",
    "print(final_State[15:30].argmax())\n",
    "print(final_State[30:34].argmax())\n",
    "print(final_State[34:49].argmax())\n",
    "print(final_State[49:64].argmax())\n",
    "exampleEnv.performAction(np.argmax(actions.data.numpy()[0]))\n",
    "exampleEnv.performAction(np.argmax(actions.data.numpy()[1]))\n",
    "exampleEnv.performAction(np.argmax(actions.data.numpy()[2]))\n",
    "exampleEnv.performAction(np.argmax(actions.data.numpy()[3]))\n",
    "exampleEnv.performAction(np.argmax(actions.data.numpy()[4]))\n",
    "# exampleEnv.performAction(np.argmax(actions.data.numpy()[3]))\n",
    "print(exampleEnv.getStateRep(oneHotOutput=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
