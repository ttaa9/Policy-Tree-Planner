{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SimpleTask import SimpleGridTask\n",
    "import numpy as np, numpy.random as npr, random as r, SimpleTask\n",
    "from TransportTask import TransportTask\n",
    "from NavTask import NavigationTask\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import time\n",
    "from SeqData import SeqData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ForwardModel():\n",
    "    def __init__(self, \n",
    "                obs_space, \n",
    "                input_space,\n",
    "                n_hidden=100\n",
    "                ):\n",
    "        self.n_hidden=n_hidden\n",
    "        self.act_space=input_space-obs_space\n",
    "        self.obs_space=obs_space\n",
    "        #Placeholders \n",
    "        self.input = tf.placeholder(\"float\", [None, input_space])\n",
    "        self.truevalue = tf.placeholder(\"float\", [None, obs_space])\n",
    "        self.pred=self.build_graph(self.input)\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def loss_function(self,batch_size,env):\n",
    "        accTotal=0\n",
    "        cost=0\n",
    "        for i in range(0,batch_size):\n",
    "            predVecs = env.deconcatenateOneHotStateVector(self.pred[i,:])\n",
    "            labelVecs = env.deconcatenateOneHotStateVector(self.truevalue[i,:])\n",
    "            for pv,lv in zip(predVecs,labelVecs):\n",
    "                cost += tf.nn.softmax_cross_entropy_with_logits(logits=pv, labels=lv)\n",
    "                accTotal += tf.cast(tf.equal(tf.argmax(pv,axis=0), tf.argmax(lv,axis=0)), tf.float32)\n",
    "        return cost,accTotal\n",
    "    \n",
    "    def build_graph(self,inputVec, reuse=None):\n",
    "        with tf.variable_scope(\"forward-model\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(inputVec, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            hidden2 = slim.fully_connected(hidden, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            return slim.fully_connected(hidden2,self.obs_space, activation_fn=None, biases_initializer=None)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        sess= tf.get_default_session()\n",
    "        #x.shape = (1,n_steps, n_input)\n",
    "        return sess.run([self.pred], {self.input:x})\n",
    "\n",
    "    def load_model(self,model_file_name):\n",
    "        sess= tf.get_default_session()\n",
    "        self.saver.restore(sess, model_file_name)\n",
    "\n",
    "    def train(self,trainset,testset,training_steps,batch_size,env,learning_rate,display_step, model_file_name=\"FWR_model_\"+time.strftime(\"%Y%m%d-%H%M%S\")):\n",
    "        sess= tf.get_default_session()\n",
    "        print('Entering loss func')\n",
    "        cost,accTotal = self.loss_function(batch_size,env)\n",
    "        print('Defining optimizer')\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "        self.accuracy = accTotal / (batch_size * trainset.env.stateSubVectors) #tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        print('Running TF initializer')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        noise_sigma = 0.3\n",
    "        print('Entering train loop')\n",
    "        for step in range(1, training_steps + 1):\n",
    "            batch_x, batch_y = trainset.next_batch_nonseq(batch_size)\n",
    "            # npbx = np.array( batch_x )\n",
    "            # npbxs = npbx.shape\n",
    "            # noise = noise_sigma * np.random.randn( npbxs[0], npbxs[1] )\n",
    "            # batch_x += noise\n",
    "            sess.run(self.optimizer, feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy & loss\n",
    "                acc, loss = sess.run([self.accuracy, cost], feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "                print(\"Step \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Calculate accuracy\n",
    "        test_data, test_label = testset.next_batch_nonseq(5000) \n",
    "        acc=sess.run(self.accuracy, feed_dict={self.input: test_data, self.truevalue: test_label})\n",
    "        print(\"Testing Accuracy:\",acc)\n",
    "        save_path= self.saver.save(sess, \"./\"+model_file_name+\".ckpt\")\n",
    "        print(\"Model Saved\")\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('Reading Data')\n",
    "    s = 'navigation' #'navigation'\n",
    "    trainf, validf = s+\"-data-train-small.pickle\", s+\"-data-test-small.pickle\"\n",
    "    train, test   = SeqData(trainf), SeqData(validf)\n",
    "    \n",
    "    # classType = NavigationTask if s == 'navigation' else TransportTask\n",
    "    print(train.env.stateSubVectors)\n",
    "    print('Defining Model')\n",
    "    # Parameters\n",
    "    learning_rate = 0.0005\n",
    "    training_steps = 15000 #2000 # 10000\n",
    "    batch_size = 64 #256 #128\n",
    "    display_step = 200\n",
    "    # Network Parameters\n",
    "    n_hidden = 200 #128 #5*train.lenOfInput # hidden layer num of features\n",
    "    len_state = train.lenOfState # linear sequence or not\n",
    "    len_input = train.lenOfInput\n",
    "\n",
    "    print('Initializing FM')\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        fm=ForwardModel(len_state,len_input, n_hidden)\n",
    "        print('FM initialized')\n",
    "        fm.train(train,test,training_steps,batch_size,train.env,learning_rate,display_step,\"trained_model_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n",
      "5\n",
      "Defining Model\n",
      "Initializing FM\n",
      "FM initialized\n",
      "Entering loss func\n",
      "Defining optimizer\n",
      "Running TF initializer\n",
      "Entering train loop\n",
      "Step 64, Minibatch Loss= 779.468323, Training Accuracy= 0.08750\n",
      "Step 12800, Minibatch Loss= 221.971603, Training Accuracy= 0.91562\n",
      "Step 25600, Minibatch Loss= 93.502754, Training Accuracy= 0.94687\n",
      "Step 38400, Minibatch Loss= 87.324150, Training Accuracy= 0.94687\n",
      "Step 51200, Minibatch Loss= 96.650108, Training Accuracy= 0.92500\n",
      "Step 64000, Minibatch Loss= 81.491425, Training Accuracy= 0.93437\n",
      "Step 76800, Minibatch Loss= 76.359688, Training Accuracy= 0.93750\n",
      "Step 89600, Minibatch Loss= 58.662125, Training Accuracy= 0.94687\n",
      "Step 102400, Minibatch Loss= 89.629333, Training Accuracy= 0.90312\n",
      "Step 115200, Minibatch Loss= 63.239368, Training Accuracy= 0.94375\n",
      "Step 128000, Minibatch Loss= 38.974918, Training Accuracy= 0.95625\n",
      "Step 140800, Minibatch Loss= 51.166157, Training Accuracy= 0.94375\n",
      "Step 153600, Minibatch Loss= 37.913792, Training Accuracy= 0.95938\n",
      "Step 166400, Minibatch Loss= 31.870375, Training Accuracy= 0.96250\n",
      "Step 179200, Minibatch Loss= 28.729504, Training Accuracy= 0.97188\n",
      "Step 192000, Minibatch Loss= 32.370861, Training Accuracy= 0.96562\n",
      "Step 204800, Minibatch Loss= 21.408228, Training Accuracy= 0.98438\n",
      "Step 217600, Minibatch Loss= 22.617523, Training Accuracy= 0.97500\n",
      "Step 230400, Minibatch Loss= 22.739677, Training Accuracy= 0.97812\n",
      "Step 243200, Minibatch Loss= 25.050718, Training Accuracy= 0.97188\n",
      "Step 256000, Minibatch Loss= 25.280872, Training Accuracy= 0.98438\n",
      "Step 268800, Minibatch Loss= 23.906130, Training Accuracy= 0.97500\n",
      "Step 281600, Minibatch Loss= 19.259317, Training Accuracy= 0.97188\n",
      "Step 294400, Minibatch Loss= 13.374277, Training Accuracy= 0.99375\n",
      "Step 307200, Minibatch Loss= 7.228173, Training Accuracy= 0.99687\n",
      "Step 320000, Minibatch Loss= 10.050519, Training Accuracy= 0.99375\n",
      "Step 332800, Minibatch Loss= 7.582764, Training Accuracy= 1.00000\n",
      "Step 345600, Minibatch Loss= 8.406161, Training Accuracy= 1.00000\n",
      "Step 358400, Minibatch Loss= 5.798552, Training Accuracy= 0.99687\n",
      "Step 371200, Minibatch Loss= 4.474121, Training Accuracy= 1.00000\n",
      "Step 384000, Minibatch Loss= 3.304446, Training Accuracy= 1.00000\n",
      "Step 396800, Minibatch Loss= 3.530751, Training Accuracy= 1.00000\n",
      "Step 409600, Minibatch Loss= 2.708794, Training Accuracy= 1.00000\n",
      "Step 422400, Minibatch Loss= 1.784887, Training Accuracy= 1.00000\n",
      "Step 435200, Minibatch Loss= 2.694766, Training Accuracy= 1.00000\n",
      "Step 448000, Minibatch Loss= 2.162574, Training Accuracy= 1.00000\n",
      "Step 460800, Minibatch Loss= 1.451880, Training Accuracy= 1.00000\n",
      "Step 473600, Minibatch Loss= 0.893516, Training Accuracy= 1.00000\n",
      "Step 486400, Minibatch Loss= 1.201632, Training Accuracy= 1.00000\n",
      "Step 499200, Minibatch Loss= 1.141241, Training Accuracy= 1.00000\n",
      "Step 512000, Minibatch Loss= 0.529058, Training Accuracy= 1.00000\n",
      "Step 524800, Minibatch Loss= 0.410425, Training Accuracy= 1.00000\n",
      "Step 537600, Minibatch Loss= 0.499151, Training Accuracy= 1.00000\n",
      "Step 550400, Minibatch Loss= 0.493549, Training Accuracy= 1.00000\n",
      "Step 563200, Minibatch Loss= 0.279713, Training Accuracy= 1.00000\n",
      "Step 576000, Minibatch Loss= 0.385689, Training Accuracy= 1.00000\n",
      "Step 588800, Minibatch Loss= 0.228688, Training Accuracy= 1.00000\n",
      "Step 601600, Minibatch Loss= 0.269984, Training Accuracy= 1.00000\n",
      "Step 614400, Minibatch Loss= 0.215246, Training Accuracy= 1.00000\n",
      "Step 627200, Minibatch Loss= 0.171806, Training Accuracy= 1.00000\n",
      "Step 640000, Minibatch Loss= 0.085110, Training Accuracy= 1.00000\n",
      "Step 652800, Minibatch Loss= 0.164154, Training Accuracy= 1.00000\n",
      "Step 665600, Minibatch Loss= 0.131088, Training Accuracy= 1.00000\n",
      "Step 678400, Minibatch Loss= 0.109535, Training Accuracy= 1.00000\n",
      "Step 691200, Minibatch Loss= 0.076581, Training Accuracy= 1.00000\n",
      "Step 704000, Minibatch Loss= 0.105308, Training Accuracy= 1.00000\n",
      "Step 716800, Minibatch Loss= 0.089906, Training Accuracy= 1.00000\n",
      "Step 729600, Minibatch Loss= 0.056587, Training Accuracy= 1.00000\n",
      "Step 742400, Minibatch Loss= 0.041792, Training Accuracy= 1.00000\n",
      "Step 755200, Minibatch Loss= 0.050781, Training Accuracy= 1.00000\n",
      "Step 768000, Minibatch Loss= 0.059219, Training Accuracy= 1.00000\n",
      "Step 780800, Minibatch Loss= 0.044169, Training Accuracy= 1.00000\n",
      "Step 793600, Minibatch Loss= 0.035437, Training Accuracy= 1.00000\n",
      "Step 806400, Minibatch Loss= 0.035219, Training Accuracy= 1.00000\n",
      "Step 819200, Minibatch Loss= 0.042264, Training Accuracy= 1.00000\n",
      "Step 832000, Minibatch Loss= 0.025713, Training Accuracy= 1.00000\n",
      "Step 844800, Minibatch Loss= 0.025588, Training Accuracy= 1.00000\n",
      "Step 857600, Minibatch Loss= 0.017264, Training Accuracy= 1.00000\n",
      "Step 870400, Minibatch Loss= 0.020329, Training Accuracy= 1.00000\n",
      "Step 883200, Minibatch Loss= 0.011268, Training Accuracy= 1.00000\n",
      "Step 896000, Minibatch Loss= 0.012452, Training Accuracy= 1.00000\n",
      "Step 908800, Minibatch Loss= 0.014994, Training Accuracy= 1.00000\n",
      "Step 921600, Minibatch Loss= 0.010227, Training Accuracy= 1.00000\n",
      "Step 934400, Minibatch Loss= 0.014581, Training Accuracy= 1.00000\n",
      "Step 947200, Minibatch Loss= 0.019413, Training Accuracy= 1.00000\n",
      "Step 960000, Minibatch Loss= 0.024418, Training Accuracy= 1.00000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(input_value):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        fm=ForwardModel(64,74,200)\n",
    "        fm.load_model('trained_model_1.ckpt')\n",
    "        result = fm.build_graph(input_value, reuse=True)\n",
    "\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Inital State: \")\n",
    "        print(np.argmax(input_value[0][0:15]))\n",
    "        print(np.argmax(input_value[0][15:30]))\n",
    "        print(np.argmax(input_value[0][30:34]))\n",
    "        print(np.argmax(input_value[0][34:49]))\n",
    "        print(np.argmax(input_value[0][49:64]))\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Action: \")\n",
    "        print(np.argmax(input_value[0][64:74]))\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "        result = sess.run(result)\n",
    "        #print(sess.run(result))\n",
    "        print(\"Result: \")\n",
    "        print(np.argmax(result[0][0:15]))\n",
    "        print(np.argmax(result[0][15:30]))\n",
    "        print(np.argmax(result[0][30:34]))\n",
    "        print(np.argmax(result[0][34:49]))\n",
    "        print(np.argmax(result[0][49:64]))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing actions and  state\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "0\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "1\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "2\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "1\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "3\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "2\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "3\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "5\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "1\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "6\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "7\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "3\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "8\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "4\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "9\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "5\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test cases 1\n",
    "print(\"Testing actions and  state\")\n",
    "print(\"-----\")\n",
    "for i in range(0,10):\n",
    "    env = NavigationTask() #(stochasticity=0.2)\n",
    "    state_i=env.getStateRep()\n",
    "    index = np.array([i])\n",
    "    a_s = np.zeros((10))\n",
    "    a_s[index] = 1\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    run(input_value)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different inital state and actions\n",
      "-----\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "3\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "0\n",
      "---------------------------\n",
      "Result: \n",
      "3\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "8\n",
      "12\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "1\n",
      "---------------------------\n",
      "Result: \n",
      "8\n",
      "12\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "13\n",
      "6\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "2\n",
      "---------------------------\n",
      "Result: \n",
      "13\n",
      "6\n",
      "1\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "8\n",
      "1\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "3\n",
      "---------------------------\n",
      "Result: \n",
      "8\n",
      "1\n",
      "2\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "10\n",
      "9\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "10\n",
      "9\n",
      "3\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "12\n",
      "7\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "5\n",
      "---------------------------\n",
      "Result: \n",
      "12\n",
      "8\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "13\n",
      "10\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "6\n",
      "---------------------------\n",
      "Result: \n",
      "13\n",
      "12\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "1\n",
      "10\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "7\n",
      "---------------------------\n",
      "Result: \n",
      "1\n",
      "13\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "8\n",
      "7\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "8\n",
      "---------------------------\n",
      "Result: \n",
      "8\n",
      "11\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "12\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "9\n",
      "---------------------------\n",
      "Result: \n",
      "12\n",
      "7\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test cases 2\n",
    "print(\"Testing different inital state and actions\")\n",
    "print(\"-----\")\n",
    "for i in range(0,10):\n",
    "    h = np.random.randint(14, size=1)[0]\n",
    "    w = np.random.randint(14, size=1)[0]\n",
    "    env = NavigationTask(agent_start_pos=[np.array([h,w]),'N']) #(stochasticity=0.2)\n",
    "    state_i=env.getStateRep()\n",
    "    index = np.array([i])\n",
    "    a_s = np.zeros((10))\n",
    "    a_s[index] = 1\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    run(input_value)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing path of states\n",
      "-----\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "3\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "3\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "3\n",
      "8\n",
      "10\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_1.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "3\n",
      "8\n",
      "10\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "2\n",
      "3\n",
      "8\n",
      "10\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test cases 3\n",
    "print(\"Testing path of states\")\n",
    "print(\"-----\")\n",
    "env = NavigationTask() #(stochasticity=0.2)\n",
    "state_i=env.getStateRep()\n",
    "for i in range(0,3):\n",
    "    k = np.random.randint(9, size=1)[0]\n",
    "    index = np.array([k])\n",
    "    a_s = np.zeros((10))\n",
    "    a_s[index] = 1\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    state_i = run(input_value)[0]\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ForwardModelWithNoise():\n",
    "    def __init__(self, \n",
    "                obs_space, \n",
    "                input_space,\n",
    "                n_hidden=100\n",
    "                ):\n",
    "        self.n_hidden=n_hidden\n",
    "        self.act_space=input_space-obs_space\n",
    "        self.obs_space=obs_space\n",
    "        #Placeholders \n",
    "        self.input = tf.placeholder(\"float\", [None, input_space])\n",
    "        self.truevalue = tf.placeholder(\"float\", [None, obs_space])\n",
    "        self.pred=self.build_graph(self.input)\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def loss_function(self,batch_size,env):\n",
    "        accTotal=0\n",
    "        cost=0\n",
    "        for i in range(0,batch_size):\n",
    "            predVecs = env.deconcatenateOneHotStateVector(self.pred[i,:])\n",
    "            labelVecs = env.deconcatenateOneHotStateVector(self.truevalue[i,:])\n",
    "            for pv,lv in zip(predVecs,labelVecs):\n",
    "                cost += tf.nn.softmax_cross_entropy_with_logits(logits=pv, labels=lv)\n",
    "                accTotal += tf.cast(tf.equal(tf.argmax(pv,axis=0), tf.argmax(lv,axis=0)), tf.float32)\n",
    "        return cost,accTotal\n",
    "    \n",
    "    def build_graph(self,inputVec, reuse=None):\n",
    "        with tf.variable_scope(\"forward-model\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(inputVec, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            hidden2 = slim.fully_connected(hidden, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            return slim.fully_connected(hidden2,self.obs_space, activation_fn=None, biases_initializer=None)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        sess= tf.get_default_session()\n",
    "        #x.shape = (1,n_steps, n_input)\n",
    "        return sess.run([self.pred], {self.input:x})\n",
    "\n",
    "    def load_model(self,model_file_name):\n",
    "        sess= tf.get_default_session()\n",
    "        self.saver.restore(sess, model_file_name)\n",
    "\n",
    "    def train(self,trainset,testset,training_steps,batch_size,env,learning_rate,display_step, model_file_name=\"FWR_model_\"+time.strftime(\"%Y%m%d-%H%M%S\")):\n",
    "        sess= tf.get_default_session()\n",
    "        print('Entering loss func')\n",
    "        cost,accTotal = self.loss_function(batch_size,env)\n",
    "        print('Defining optimizer')\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "        self.accuracy = accTotal / (batch_size * trainset.env.stateSubVectors) #tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        print('Running TF initializer')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        noise_sigma = 0.1\n",
    "        print('Entering train loop')\n",
    "        for step in range(1, training_steps + 1):\n",
    "            batch_x, batch_y = trainset.next_batch_nonseq(batch_size)\n",
    "            npbx = np.array( batch_x )\n",
    "            npbxs = npbx.shape\n",
    "            noise = noise_sigma * np.random.randn( npbxs[0], npbxs[1] )\n",
    "            batch_x += noise\n",
    "            sess.run(self.optimizer, feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy & loss\n",
    "                acc, loss = sess.run([self.accuracy, cost], feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "                print(\"Step \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Calculate accuracy\n",
    "        test_data, test_label = testset.next_batch_nonseq(5000) \n",
    "        acc=sess.run(self.accuracy, feed_dict={self.input: test_data, self.truevalue: test_label})\n",
    "        print(\"Testing Accuracy:\",acc)\n",
    "        save_path= self.saver.save(sess, \"./\"+model_file_name+\".ckpt\")\n",
    "        print(\"Model Saved\")\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main2():\n",
    "    print('Reading Data')\n",
    "    s = 'navigation' #'navigation'\n",
    "    trainf, validf = s+\"-data-train-small.pickle\", s+\"-data-test-small.pickle\"\n",
    "    train, test   = SeqData(trainf), SeqData(validf)\n",
    "    \n",
    "    # classType = NavigationTask if s == 'navigation' else TransportTask\n",
    "    print(train.env.stateSubVectors)\n",
    "    print('Defining Model')\n",
    "    # Parameters\n",
    "    learning_rate = 0.0005\n",
    "    training_steps = 15000 #2000 # 10000\n",
    "    batch_size = 64 #256 #128\n",
    "    display_step = 200\n",
    "    # Network Parameters\n",
    "    n_hidden = 200 #128 #5*train.lenOfInput # hidden layer num of features\n",
    "    len_state = train.lenOfState # linear sequence or not\n",
    "    len_input = train.lenOfInput\n",
    "\n",
    "    print('Initializing FM')\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        fm=ForwardModelWithNoise(len_state,len_input, n_hidden)\n",
    "        print('FM initialized')\n",
    "        fm.train(train,test,training_steps,batch_size,train.env,learning_rate,display_step,\"trained_model_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n",
      "5\n",
      "Defining Model\n",
      "Initializing FM\n",
      "FM initialized\n",
      "Entering loss func\n",
      "Defining optimizer\n",
      "Running TF initializer\n",
      "Entering train loop\n",
      "Step 64, Minibatch Loss= 779.819275, Training Accuracy= 0.10000\n",
      "Step 12800, Minibatch Loss= 251.343781, Training Accuracy= 0.90625\n",
      "Step 25600, Minibatch Loss= 152.013504, Training Accuracy= 0.91250\n",
      "Step 38400, Minibatch Loss= 115.781525, Training Accuracy= 0.91875\n",
      "Step 51200, Minibatch Loss= 109.605118, Training Accuracy= 0.92188\n",
      "Step 64000, Minibatch Loss= 106.370415, Training Accuracy= 0.92813\n",
      "Step 76800, Minibatch Loss= 98.728577, Training Accuracy= 0.92188\n",
      "Step 89600, Minibatch Loss= 104.499077, Training Accuracy= 0.91562\n",
      "Step 102400, Minibatch Loss= 84.629402, Training Accuracy= 0.92813\n",
      "Step 115200, Minibatch Loss= 91.076355, Training Accuracy= 0.92813\n",
      "Step 128000, Minibatch Loss= 87.292824, Training Accuracy= 0.92813\n",
      "Step 140800, Minibatch Loss= 84.974991, Training Accuracy= 0.92188\n",
      "Step 153600, Minibatch Loss= 69.507217, Training Accuracy= 0.93750\n",
      "Step 166400, Minibatch Loss= 87.824196, Training Accuracy= 0.90625\n",
      "Step 179200, Minibatch Loss= 71.979004, Training Accuracy= 0.93750\n",
      "Step 192000, Minibatch Loss= 77.458000, Training Accuracy= 0.93437\n",
      "Step 204800, Minibatch Loss= 41.466736, Training Accuracy= 0.95625\n",
      "Step 217600, Minibatch Loss= 52.126312, Training Accuracy= 0.93437\n",
      "Step 230400, Minibatch Loss= 57.908848, Training Accuracy= 0.93750\n",
      "Step 243200, Minibatch Loss= 45.510784, Training Accuracy= 0.95312\n",
      "Step 256000, Minibatch Loss= 66.130867, Training Accuracy= 0.93125\n",
      "Step 268800, Minibatch Loss= 48.434963, Training Accuracy= 0.95312\n",
      "Step 281600, Minibatch Loss= 47.264614, Training Accuracy= 0.94687\n",
      "Step 294400, Minibatch Loss= 24.780451, Training Accuracy= 0.98125\n",
      "Step 307200, Minibatch Loss= 49.047115, Training Accuracy= 0.95000\n",
      "Step 320000, Minibatch Loss= 37.206009, Training Accuracy= 0.96250\n",
      "Step 332800, Minibatch Loss= 37.740780, Training Accuracy= 0.95938\n",
      "Step 345600, Minibatch Loss= 31.847717, Training Accuracy= 0.96250\n",
      "Step 358400, Minibatch Loss= 29.174162, Training Accuracy= 0.97812\n",
      "Step 371200, Minibatch Loss= 34.582306, Training Accuracy= 0.96250\n",
      "Step 384000, Minibatch Loss= 20.925388, Training Accuracy= 0.97500\n",
      "Step 396800, Minibatch Loss= 16.169498, Training Accuracy= 0.99063\n",
      "Step 409600, Minibatch Loss= 24.069218, Training Accuracy= 0.97812\n",
      "Step 422400, Minibatch Loss= 22.739254, Training Accuracy= 0.97500\n",
      "Step 435200, Minibatch Loss= 17.246130, Training Accuracy= 0.98438\n",
      "Step 448000, Minibatch Loss= 16.991234, Training Accuracy= 0.98438\n",
      "Step 460800, Minibatch Loss= 18.716698, Training Accuracy= 0.98125\n",
      "Step 473600, Minibatch Loss= 19.411531, Training Accuracy= 0.97812\n",
      "Step 486400, Minibatch Loss= 11.920997, Training Accuracy= 0.98750\n",
      "Step 499200, Minibatch Loss= 7.826122, Training Accuracy= 0.99687\n",
      "Step 512000, Minibatch Loss= 14.153768, Training Accuracy= 0.98438\n",
      "Step 524800, Minibatch Loss= 13.037411, Training Accuracy= 0.98750\n",
      "Step 537600, Minibatch Loss= 13.591721, Training Accuracy= 0.98438\n",
      "Step 550400, Minibatch Loss= 6.490236, Training Accuracy= 0.99687\n",
      "Step 563200, Minibatch Loss= 8.080178, Training Accuracy= 0.99063\n",
      "Step 576000, Minibatch Loss= 12.127897, Training Accuracy= 0.99063\n",
      "Step 588800, Minibatch Loss= 9.127482, Training Accuracy= 0.99063\n",
      "Step 601600, Minibatch Loss= 9.698665, Training Accuracy= 0.99375\n",
      "Step 614400, Minibatch Loss= 7.925514, Training Accuracy= 0.99063\n",
      "Step 627200, Minibatch Loss= 9.413504, Training Accuracy= 0.99375\n",
      "Step 640000, Minibatch Loss= 8.625793, Training Accuracy= 0.99063\n",
      "Step 652800, Minibatch Loss= 6.074018, Training Accuracy= 0.99687\n",
      "Step 665600, Minibatch Loss= 4.177216, Training Accuracy= 0.99687\n",
      "Step 678400, Minibatch Loss= 5.373511, Training Accuracy= 0.99687\n",
      "Step 691200, Minibatch Loss= 5.887294, Training Accuracy= 0.99687\n",
      "Step 704000, Minibatch Loss= 5.866109, Training Accuracy= 0.99375\n",
      "Step 716800, Minibatch Loss= 1.908300, Training Accuracy= 1.00000\n",
      "Step 729600, Minibatch Loss= 3.373807, Training Accuracy= 1.00000\n",
      "Step 742400, Minibatch Loss= 4.203200, Training Accuracy= 1.00000\n",
      "Step 755200, Minibatch Loss= 6.696316, Training Accuracy= 0.99687\n",
      "Step 768000, Minibatch Loss= 3.518987, Training Accuracy= 0.99687\n",
      "Step 780800, Minibatch Loss= 4.772113, Training Accuracy= 0.99687\n",
      "Step 793600, Minibatch Loss= 5.979754, Training Accuracy= 0.99375\n",
      "Step 806400, Minibatch Loss= 2.143072, Training Accuracy= 1.00000\n",
      "Step 819200, Minibatch Loss= 2.171742, Training Accuracy= 1.00000\n",
      "Step 832000, Minibatch Loss= 2.195665, Training Accuracy= 1.00000\n",
      "Step 844800, Minibatch Loss= 2.111149, Training Accuracy= 1.00000\n",
      "Step 857600, Minibatch Loss= 7.180540, Training Accuracy= 0.99063\n",
      "Step 870400, Minibatch Loss= 4.074256, Training Accuracy= 0.99687\n",
      "Step 883200, Minibatch Loss= 3.365018, Training Accuracy= 0.99687\n",
      "Step 896000, Minibatch Loss= 1.973794, Training Accuracy= 1.00000\n",
      "Step 908800, Minibatch Loss= 2.799560, Training Accuracy= 1.00000\n",
      "Step 921600, Minibatch Loss= 2.275199, Training Accuracy= 1.00000\n",
      "Step 934400, Minibatch Loss= 2.103955, Training Accuracy= 1.00000\n",
      "Step 947200, Minibatch Loss= 7.127419, Training Accuracy= 0.99375\n",
      "Step 960000, Minibatch Loss= 4.467632, Training Accuracy= 0.99687\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "main2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run2(input_value):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        fm=ForwardModelWithNoise(64,74,200)\n",
    "        fm.load_model('trained_model_2.ckpt')\n",
    "        result = fm.build_graph(input_value, reuse=True)\n",
    "\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Inital State: \")\n",
    "        print(np.argmax(input_value[0][0:15]))\n",
    "        print(np.argmax(input_value[0][15:30]))\n",
    "        print(np.argmax(input_value[0][30:34]))\n",
    "        print(np.argmax(input_value[0][34:49]))\n",
    "        print(np.argmax(input_value[0][49:64]))\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Action: \")\n",
    "        print(np.argmax(input_value[0][64:74]))\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "        result = sess.run(result)\n",
    "        #print(sess.run(result))\n",
    "        print(\"Result: \")\n",
    "        print(np.argmax(result[0][0:15]))\n",
    "        print(np.argmax(result[0][15:30]))\n",
    "        print(np.argmax(result[0][30:34]))\n",
    "        print(np.argmax(result[0][34:49]))\n",
    "        print(np.argmax(result[0][49:64]))\n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing actions and  state\n",
      "-----\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "0\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "1\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "2\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "1\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "3\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "2\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "0\n",
      "3\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "5\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "1\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "6\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "7\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "3\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "8\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "4\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "9\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "5\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test cases 1\n",
    "print(\"Testing actions and  state\")\n",
    "print(\"-----\")\n",
    "for i in range(0,10):\n",
    "    env = NavigationTask() #(stochasticity=0.2)\n",
    "    state_i=env.getStateRep()\n",
    "    index = np.array([i])\n",
    "    a_s = np.zeros((10))\n",
    "    a_s[index] = 1\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    run2(input_value)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing path of states\n",
      "-----\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "6\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "1\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "3\n",
      "2\n",
      "9\n",
      "4\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "3\n",
      "2\n",
      "9\n",
      "4\n",
      "---------------------------\n",
      "Action: \n",
      "5\n",
      "---------------------------\n",
      "Result: \n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "7\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test cases 3\n",
    "print(\"Testing path of states\")\n",
    "print(\"-----\")\n",
    "env = NavigationTask() #(stochasticity=0.2)\n",
    "state_i=env.getStateRep()\n",
    "for i in range(0,3):\n",
    "    k = np.random.randint(9, size=1)[0]\n",
    "    index = np.array([k])\n",
    "    a_s = np.zeros((10))\n",
    "    a_s[index] = 1\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    state_i = run2(input_value)[0]\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "    U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "    return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    y = logits + sample_gumbel(tf.shape(logits))\n",
    "    return tf.nn.softmax( y / temperature)\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ForwardModelDifferentLoss():\n",
    "    def __init__(self, \n",
    "                obs_space, \n",
    "                input_space,\n",
    "                n_hidden=100\n",
    "                ):\n",
    "        self.n_hidden=n_hidden\n",
    "        self.act_space=input_space-obs_space\n",
    "        self.obs_space=obs_space\n",
    "        #Placeholders \n",
    "        self.input = tf.placeholder(\"float\", [None, input_space])\n",
    "        self.truevalue = tf.placeholder(\"float\", [None, obs_space])\n",
    "        self.pred=self.build_graph(self.input)\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "    def loss_function(self,batch_size,env):\n",
    "        accTotal=0\n",
    "        cost=0\n",
    "        for i in range(0,batch_size):\n",
    "            predVecs = env.deconcatenateOneHotStateVector(self.pred[i,:])\n",
    "            labelVecs = env.deconcatenateOneHotStateVector(self.truevalue[i,:])\n",
    "            for pv,lv in zip(predVecs,labelVecs):\n",
    "                #cost += tf.nn.softmax_cross_entropy_with_logits(logits=pv, labels=lv)\n",
    "                accTotal += tf.cast(tf.equal(tf.argmax(pv,axis=0), tf.argmax(lv,axis=0)), tf.float32)\n",
    "        cost =  tf.reduce_mean(tf.pow(self.pred - self.truevalue, 2))\n",
    "        return cost,accTotal\n",
    "\n",
    "    \n",
    "    def build_graph(self,inputVec, reuse=None):\n",
    "        with tf.variable_scope(\"forward-model\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(inputVec, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            hidden2 = slim.fully_connected(hidden, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            return slim.fully_connected(hidden2,self.obs_space, activation_fn=None, biases_initializer=None)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        sess= tf.get_default_session()\n",
    "        #x.shape = (1,n_steps, n_input)\n",
    "        return sess.run([self.pred], {self.input:x})\n",
    "\n",
    "    def load_model(self,model_file_name):\n",
    "        sess= tf.get_default_session()\n",
    "        self.saver.restore(sess, model_file_name)\n",
    "\n",
    "    def train(self,trainset,testset,training_steps,batch_size,env,learning_rate,display_step, model_file_name=\"FWR_model_\"+time.strftime(\"%Y%m%d-%H%M%S\")):\n",
    "        sess= tf.get_default_session()\n",
    "        print('Entering loss func')\n",
    "        cost,accTotal = self.loss_function(batch_size,env)\n",
    "        print('Defining optimizer')\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "        self.accuracy = accTotal / (batch_size * trainset.env.stateSubVectors) #tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        print('Running TF initializer')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        noise_sigma = 0.2\n",
    "        print('Entering train loop')\n",
    "        for step in range(1, training_steps + 1):\n",
    "            batch_x, batch_y = trainset.next_batch_nonseq(batch_size)\n",
    "            npbx = np.array( batch_x )\n",
    "            npbxs = npbx.shape\n",
    "            noise = noise_sigma * np.random.randn( npbxs[0], npbxs[1] )\n",
    "            batch_x += noise\n",
    "            sess.run(self.optimizer, feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy & loss\n",
    "                acc, loss = sess.run([self.accuracy, cost], feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "                print(\"Step \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Calculate accuracy\n",
    "        test_data, test_label = testset.next_batch_nonseq(5000) \n",
    "        acc=sess.run(self.accuracy, feed_dict={self.input: test_data, self.truevalue: test_label})\n",
    "        print(\"Testing Accuracy:\",acc)\n",
    "        save_path= self.saver.save(sess, \"./\"+model_file_name+\".ckpt\")\n",
    "        print(\"Model Saved\")\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main3():\n",
    "    print('Reading Data')\n",
    "    s = 'navigation' #'navigation'\n",
    "    trainf, validf = s+\"-data-train-small.pickle\", s+\"-data-test-small.pickle\"\n",
    "    train, test   = SeqData(trainf), SeqData(validf)\n",
    "    \n",
    "    # classType = NavigationTask if s == 'navigation' else TransportTask\n",
    "    print(train.env.stateSubVectors)\n",
    "    print('Defining Model')\n",
    "    # Parameters\n",
    "    learning_rate = 0.0005\n",
    "    training_steps = 15000 #2000 # 10000\n",
    "    batch_size = 64 #256 #128\n",
    "    display_step = 200\n",
    "    # Network Parameters\n",
    "    n_hidden = 200 #128 #5*train.lenOfInput # hidden layer num of features\n",
    "    len_state = train.lenOfState # linear sequence or not\n",
    "    len_input = train.lenOfInput\n",
    "\n",
    "    print('Initializing FM')\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        fm=ForwardModelDifferentLoss(len_state,len_input, n_hidden)\n",
    "        print('FM initialized')\n",
    "        fm.train(train,test,training_steps,batch_size,train.env,learning_rate,display_step,\"trained_model_3_noise_0_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n",
      "5\n",
      "Defining Model\n",
      "Initializing FM\n",
      "FM initialized\n",
      "Entering loss func\n",
      "Defining optimizer\n",
      "Running TF initializer\n",
      "Entering train loop\n",
      "Step 64, Minibatch Loss= 0.100181, Training Accuracy= 0.15000\n",
      "Step 12800, Minibatch Loss= 0.042860, Training Accuracy= 0.83438\n",
      "Step 25600, Minibatch Loss= 0.035182, Training Accuracy= 0.86875\n",
      "Step 38400, Minibatch Loss= 0.032166, Training Accuracy= 0.90000\n",
      "Step 51200, Minibatch Loss= 0.030690, Training Accuracy= 0.91562\n",
      "Step 64000, Minibatch Loss= 0.030267, Training Accuracy= 0.90625\n",
      "Step 76800, Minibatch Loss= 0.028286, Training Accuracy= 0.90000\n",
      "Step 89600, Minibatch Loss= 0.026643, Training Accuracy= 0.91562\n",
      "Step 102400, Minibatch Loss= 0.027317, Training Accuracy= 0.87500\n",
      "Step 115200, Minibatch Loss= 0.024159, Training Accuracy= 0.90625\n",
      "Step 128000, Minibatch Loss= 0.021692, Training Accuracy= 0.92813\n",
      "Step 140800, Minibatch Loss= 0.022776, Training Accuracy= 0.90312\n",
      "Step 153600, Minibatch Loss= 0.020907, Training Accuracy= 0.90312\n",
      "Step 166400, Minibatch Loss= 0.018538, Training Accuracy= 0.93437\n",
      "Step 179200, Minibatch Loss= 0.020764, Training Accuracy= 0.90312\n",
      "Step 192000, Minibatch Loss= 0.020158, Training Accuracy= 0.89375\n",
      "Step 204800, Minibatch Loss= 0.017365, Training Accuracy= 0.93125\n",
      "Step 217600, Minibatch Loss= 0.016539, Training Accuracy= 0.91875\n",
      "Step 230400, Minibatch Loss= 0.016656, Training Accuracy= 0.91562\n",
      "Step 243200, Minibatch Loss= 0.015769, Training Accuracy= 0.92188\n",
      "Step 256000, Minibatch Loss= 0.016513, Training Accuracy= 0.90938\n",
      "Step 268800, Minibatch Loss= 0.013998, Training Accuracy= 0.93750\n",
      "Step 281600, Minibatch Loss= 0.013710, Training Accuracy= 0.92500\n",
      "Step 294400, Minibatch Loss= 0.012248, Training Accuracy= 0.95625\n",
      "Step 307200, Minibatch Loss= 0.014874, Training Accuracy= 0.91562\n",
      "Step 320000, Minibatch Loss= 0.012358, Training Accuracy= 0.93437\n",
      "Step 332800, Minibatch Loss= 0.012818, Training Accuracy= 0.93750\n",
      "Step 345600, Minibatch Loss= 0.012689, Training Accuracy= 0.93750\n",
      "Step 358400, Minibatch Loss= 0.013120, Training Accuracy= 0.92500\n",
      "Step 371200, Minibatch Loss= 0.015219, Training Accuracy= 0.90938\n",
      "Step 384000, Minibatch Loss= 0.014501, Training Accuracy= 0.90625\n",
      "Step 396800, Minibatch Loss= 0.011540, Training Accuracy= 0.95000\n",
      "Step 409600, Minibatch Loss= 0.014653, Training Accuracy= 0.90938\n",
      "Step 422400, Minibatch Loss= 0.012247, Training Accuracy= 0.94687\n",
      "Step 435200, Minibatch Loss= 0.012996, Training Accuracy= 0.91875\n",
      "Step 448000, Minibatch Loss= 0.012649, Training Accuracy= 0.91562\n",
      "Step 460800, Minibatch Loss= 0.011577, Training Accuracy= 0.93750\n",
      "Step 473600, Minibatch Loss= 0.013273, Training Accuracy= 0.91250\n",
      "Step 486400, Minibatch Loss= 0.010617, Training Accuracy= 0.93437\n",
      "Step 499200, Minibatch Loss= 0.009217, Training Accuracy= 0.95000\n",
      "Step 512000, Minibatch Loss= 0.009536, Training Accuracy= 0.95625\n",
      "Step 524800, Minibatch Loss= 0.009728, Training Accuracy= 0.94687\n",
      "Step 537600, Minibatch Loss= 0.009589, Training Accuracy= 0.95000\n",
      "Step 550400, Minibatch Loss= 0.010863, Training Accuracy= 0.94063\n",
      "Step 563200, Minibatch Loss= 0.009435, Training Accuracy= 0.95312\n",
      "Step 576000, Minibatch Loss= 0.011151, Training Accuracy= 0.92500\n",
      "Step 588800, Minibatch Loss= 0.010483, Training Accuracy= 0.93125\n",
      "Step 601600, Minibatch Loss= 0.011313, Training Accuracy= 0.93125\n",
      "Step 614400, Minibatch Loss= 0.010196, Training Accuracy= 0.93437\n",
      "Step 627200, Minibatch Loss= 0.012396, Training Accuracy= 0.90938\n",
      "Step 640000, Minibatch Loss= 0.010586, Training Accuracy= 0.93750\n",
      "Step 652800, Minibatch Loss= 0.011374, Training Accuracy= 0.91562\n",
      "Step 665600, Minibatch Loss= 0.010148, Training Accuracy= 0.93437\n",
      "Step 678400, Minibatch Loss= 0.009037, Training Accuracy= 0.95000\n",
      "Step 691200, Minibatch Loss= 0.009605, Training Accuracy= 0.93125\n",
      "Step 704000, Minibatch Loss= 0.010324, Training Accuracy= 0.93437\n",
      "Step 716800, Minibatch Loss= 0.008582, Training Accuracy= 0.93437\n",
      "Step 729600, Minibatch Loss= 0.009937, Training Accuracy= 0.93437\n",
      "Step 742400, Minibatch Loss= 0.009075, Training Accuracy= 0.94063\n",
      "Step 755200, Minibatch Loss= 0.009107, Training Accuracy= 0.93437\n",
      "Step 768000, Minibatch Loss= 0.009252, Training Accuracy= 0.94063\n",
      "Step 780800, Minibatch Loss= 0.008919, Training Accuracy= 0.93750\n",
      "Step 793600, Minibatch Loss= 0.009273, Training Accuracy= 0.93125\n",
      "Step 806400, Minibatch Loss= 0.009268, Training Accuracy= 0.93125\n",
      "Step 819200, Minibatch Loss= 0.009868, Training Accuracy= 0.92188\n",
      "Step 832000, Minibatch Loss= 0.008792, Training Accuracy= 0.95938\n",
      "Step 844800, Minibatch Loss= 0.009350, Training Accuracy= 0.93750\n",
      "Step 857600, Minibatch Loss= 0.010804, Training Accuracy= 0.92500\n",
      "Step 870400, Minibatch Loss= 0.009519, Training Accuracy= 0.93437\n",
      "Step 883200, Minibatch Loss= 0.009975, Training Accuracy= 0.92813\n",
      "Step 896000, Minibatch Loss= 0.007924, Training Accuracy= 0.95000\n",
      "Step 908800, Minibatch Loss= 0.009067, Training Accuracy= 0.94375\n",
      "Step 921600, Minibatch Loss= 0.008281, Training Accuracy= 0.94687\n",
      "Step 934400, Minibatch Loss= 0.008717, Training Accuracy= 0.94375\n",
      "Step 947200, Minibatch Loss= 0.008280, Training Accuracy= 0.94687\n",
      "Step 960000, Minibatch Loss= 0.008326, Training Accuracy= 0.95312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.978125\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "main3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run3(input_value):\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        fm=ForwardModelDifferentLoss(64,74,200)\n",
    "        fm.load_model('trained_model_3_noise_0_2.ckpt')\n",
    "        result = fm.build_graph(input_value, reuse=True)\n",
    "\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Inital State: \")\n",
    "        print(np.argmax(input_value[0][0:15]))\n",
    "        print(np.argmax(input_value[0][15:30]))\n",
    "        print(np.argmax(input_value[0][30:34]))\n",
    "        print(np.argmax(input_value[0][34:49]))\n",
    "        print(np.argmax(input_value[0][49:64]))\n",
    "        print(\"---------------------------\")\n",
    "        print(\"Action: \")\n",
    "        print(np.argmax(input_value[0][64:74]))\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "        result = sess.run(result)\n",
    "        #print(sess.run(result))\n",
    "        print(\"Result: \")\n",
    "        print(np.argmax(result[0][0:15]))\n",
    "        print(np.argmax(result[0][15:30]))\n",
    "        print(np.argmax(result[0][30:34]))\n",
    "        print(np.argmax(result[0][34:49]))\n",
    "        print(np.argmax(result[0][49:64]))\n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing path of states\n",
      "-----\n",
      "INFO:tensorflow:Restoring parameters from trained_model_3_noise_0_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "5\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "[  9.70046341e-01   3.75662595e-02   1.64687522e-02  -2.36040354e-03\n",
      "  -4.45783958e-02  -2.03759503e-02  -8.03286582e-02  -3.49288210e-02\n",
      "   2.82561965e-03   9.49040055e-03   2.84422971e-02   2.87823323e-02\n",
      "  -5.04236668e-04   1.06691774e-02   6.50222600e-03   1.01937644e-01\n",
      "   9.79488045e-02   1.52118102e-01   1.34145349e-01   1.27294734e-01\n",
      "   1.44979551e-01   3.39143686e-02   5.47162592e-02   4.74073552e-02\n",
      "  -5.53238392e-03   9.29718837e-04   4.66256402e-04   4.01410684e-02\n",
      "   1.81781910e-02   2.23833099e-02   8.90936494e-01   3.90470922e-02\n",
      "  -3.08213755e-04  -1.15062520e-02  -4.16978728e-03   7.63580576e-03\n",
      "  -1.70690119e-02  -3.42252757e-03  -6.95768185e-03  -1.45979971e-03\n",
      "  -1.27382278e-02   2.92120129e-03  -8.79930705e-03   1.13955215e-02\n",
      "  -7.85594806e-03   1.93723617e-03  -6.03278633e-03   8.86479020e-03\n",
      "   9.77071106e-01   1.48141757e-03  -4.28504124e-03   6.94080954e-04\n",
      "  -1.55808087e-02   4.81907465e-03  -1.35496538e-02  -8.31443071e-03\n",
      "  -4.48490586e-03  -3.11473384e-04  -1.05544738e-03   7.28392228e-03\n",
      "  -4.48595639e-03  -1.00199562e-02  -1.14124808e-02   1.00091279e+00]\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_3_noise_0_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "2\n",
      "0\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "4\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "5\n",
      "3\n",
      "14\n",
      "14\n",
      "[  8.95284593e-01   1.56641938e-03   1.43260956e-02  -2.18804218e-02\n",
      "  -2.50406154e-02  -7.36357644e-03  -1.92019474e-02  -3.59369628e-03\n",
      "   1.25447288e-02   1.37961823e-02   2.23509949e-02  -1.02302739e-02\n",
      "  -1.76001564e-02  -1.21673252e-02  -9.84917767e-03  -4.73923311e-02\n",
      "   1.13432735e-01  -1.31333619e-03   1.03457663e-02   1.23406239e-01\n",
      "   1.84175104e-01   8.68487656e-02   5.52952737e-02   3.08556482e-03\n",
      "   4.44182754e-02   3.46497260e-02   9.47546884e-02  -4.14097914e-03\n",
      "  -2.75682639e-02   1.10386692e-01  -1.64974723e-02  -2.49479562e-02\n",
      "   9.95510444e-03   8.65740895e-01  -8.74988921e-03   8.49091262e-03\n",
      "  -1.12269521e-02  -4.82290983e-03  -1.06356535e-02   4.77368012e-03\n",
      "  -7.35480338e-03   1.68623030e-03  -8.89265165e-03   1.47698373e-02\n",
      "  -1.74574032e-02  -1.07588293e-03  -9.85519774e-03  -8.02814215e-03\n",
      "   8.78490329e-01   6.27951697e-04  -5.59128541e-03  -4.54857945e-04\n",
      "  -1.37589294e-02   2.75443867e-03  -2.64494158e-02  -4.13277373e-03\n",
      "  -1.16233099e-02  -1.42460717e-02  -1.00027863e-03   2.18066573e-02\n",
      "  -1.50428312e-02  -6.34610187e-03  -1.93679426e-03   8.84126663e-01]\n",
      "-----------------------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from trained_model_3_noise_0_2.ckpt\n",
      "---------------------------\n",
      "Inital State: \n",
      "0\n",
      "5\n",
      "3\n",
      "14\n",
      "14\n",
      "---------------------------\n",
      "Action: \n",
      "6\n",
      "---------------------------\n",
      "Result: \n",
      "0\n",
      "5\n",
      "3\n",
      "14\n",
      "14\n",
      "[  8.76708269e-01  -3.00797168e-02   1.95414107e-02  -2.75227837e-02\n",
      "  -4.13455069e-02   1.40967770e-02  -6.01714477e-04   3.73401977e-02\n",
      "   2.71754265e-02   7.75734801e-03  -1.47727523e-02  -3.08805387e-02\n",
      "  -2.16749236e-02  -3.29616889e-02  -3.00576128e-02  -3.30661237e-02\n",
      "   6.02210090e-02  -4.40769643e-02   3.70232537e-02   1.73120260e-01\n",
      "   2.04550520e-01   9.39293653e-02   1.08725978e-02  -4.32266220e-02\n",
      "   5.72933964e-02   1.42119415e-02   1.34483874e-01   5.57541661e-03\n",
      "  -1.45932287e-02   3.26975472e-02  -2.29130760e-02  -1.25304768e-02\n",
      "   2.74115913e-02   7.95675099e-01  -1.53075559e-02  -3.61832790e-03\n",
      "   3.90627980e-03  -3.45588662e-04  -1.56138446e-02   5.48386993e-03\n",
      "  -4.86361049e-03   3.91733274e-03  -7.31174275e-03   2.20774300e-02\n",
      "  -1.28723327e-02  -4.57016379e-03  -9.97296162e-03  -1.80355087e-02\n",
      "   8.11759293e-01  -2.24920362e-03  -9.93352477e-03  -2.12964485e-03\n",
      "   1.26017909e-02  -1.78415794e-04  -1.62889175e-02  -6.04895316e-03\n",
      "  -4.49703541e-03  -1.48221338e-02  -7.31511414e-03  -8.84979963e-05\n",
      "  -1.47332707e-02  -1.34295505e-03  -9.76822060e-03   8.20280910e-01]\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test cases 3\n",
    "print(\"Testing path of states\")\n",
    "print(\"-----\")\n",
    "env = NavigationTask() #(stochasticity=0.2)\n",
    "state_i=env.getStateRep()\n",
    "for i in range(0,3):\n",
    "    k = np.random.randint(9, size=1)[0]\n",
    "    index = np.array([k])\n",
    "    a_s = np.zeros((10))\n",
    "    a_s[index] = 1\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    state_i = run3(input_value)[0]\n",
    "    print(state_i)\n",
    "    print(\"-----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ForwardModelSoftmax():\n",
    "    def __init__(self, \n",
    "                obs_space, \n",
    "                input_space,\n",
    "                 env,\n",
    "                 batch_size,\n",
    "                n_hidden=100\n",
    "                ):\n",
    "        self.n_hidden=n_hidden\n",
    "        self.act_space=input_space-obs_space\n",
    "        self.obs_space=obs_space\n",
    "        #Placeholders \n",
    "        self.input = tf.placeholder(\"float\", [None, input_space])\n",
    "        self.truevalue = tf.placeholder(\"float\", [None, obs_space])\n",
    "        self.pred=self.build_graph(self.input, batch_size, env)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.env = env\n",
    "        \n",
    "        \n",
    "    def loss_function(self,batch_size,env):\n",
    "        accTotal=0\n",
    "        cost=0\n",
    "        for i in range(0,batch_size):\n",
    "            predVecs = env.deconcatenateOneHotStateVector(self.pred[i,:])\n",
    "            labelVecs = env.deconcatenateOneHotStateVector(self.truevalue[i,:])\n",
    "            for pv,lv in zip(predVecs,labelVecs):\n",
    "                #cost += tf.nn.softmax_cross_entropy_with_logits(logits=pv, labels=lv)\n",
    "                accTotal += tf.cast(tf.equal(tf.argmax(pv,axis=0), tf.argmax(lv,axis=0)), tf.float32)\n",
    "        cost =  tf.reduce_mean(tf.pow(self.pred - self.truevalue, 2))\n",
    "        return cost,accTotal\n",
    "\n",
    "    \n",
    "    def build_graph(self,inputVec, batch_size, env, reuse=None):\n",
    "        print('Building Graph')\n",
    "        with tf.variable_scope(\"forward-model\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(inputVec, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            hidden2 = slim.fully_connected(hidden, self.n_hidden, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            output = slim.fully_connected(hidden2,self.obs_space, activation_fn=None, biases_initializer=None)\n",
    "            array = []\n",
    "            target = tf.zeros([batch_size,self.obs_space])\n",
    "            print('Slicing')\n",
    "            v1 = tf.nn.softmax(output[:,0:15])\n",
    "            v2 = tf.nn.softmax(output[:,15:30])\n",
    "            v3 = tf.nn.softmax(output[:,30:34])\n",
    "            v4 = tf.nn.softmax(output[:,34:49])\n",
    "            v5 = tf.nn.softmax(output[:,49:64])\n",
    "            print('Sliced')\n",
    "#             for i in range(0,batch_size):\n",
    "#                 predVecs = env.deconcatenateOneHotStateVector(output[i,:])\n",
    "#                 for pv in predVecs:\n",
    "#                     array.append(tf.nn.softmax(pv))\n",
    "#                 print(array[i])\n",
    "#                 output= output[-1 , 0:15].assign(array[i])\n",
    "                \n",
    "            return tf.concat([v1,v2,v3,v4,v5], 1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        sess= tf.get_default_session()\n",
    "        #x.shape = (1,n_steps, n_input)\n",
    "        return sess.run([self.pred], {self.input:x})\n",
    "\n",
    "    def load_model(self,model_file_name):\n",
    "        sess= tf.get_default_session()\n",
    "        self.saver.restore(sess, model_file_name)\n",
    "\n",
    "    def train(self,trainset,testset,training_steps,batch_size,env,learning_rate,display_step, model_file_name=\"FWR_model_\"+time.strftime(\"%Y%m%d-%H%M%S\")):\n",
    "        sess= tf.get_default_session()\n",
    "        print('Entering loss func')\n",
    "        cost,accTotal = self.loss_function(batch_size,env)\n",
    "        print('Defining optimizer')\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "        self.accuracy = accTotal / (batch_size * trainset.env.stateSubVectors) #tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        print('Running TF initializer')\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        noise_sigma = 0.2\n",
    "        print('Entering train loop')\n",
    "        for step in range(1, training_steps + 1):\n",
    "            batch_x, batch_y = trainset.next_batch_nonseq(batch_size)\n",
    "            npbx = np.array( batch_x )\n",
    "            npbxs = npbx.shape\n",
    "            noise = noise_sigma * np.random.randn( npbxs[0], npbxs[1] )\n",
    "            batch_x += noise\n",
    "            sess.run(self.optimizer, feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch accuracy & loss\n",
    "                acc, loss = sess.run([self.accuracy, cost], feed_dict={self.input: batch_x, self.truevalue: batch_y})\n",
    "                print(\"Step \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Calculate accuracy\n",
    "        test_data, test_label = testset.next_batch_nonseq(5000) \n",
    "        acc=sess.run(self.accuracy, feed_dict={self.input: test_data, self.truevalue: test_label})\n",
    "        print(\"Testing Accuracy:\",acc)\n",
    "        save_path= self.saver.save(sess, \"./\"+model_file_name+\".ckpt\")\n",
    "        print(\"Model Saved\")\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main4():\n",
    "    print('Reading Data')\n",
    "    s = 'navigation' #'navigation'\n",
    "    trainf, validf = s+\"-data-train-small.pickle\", s+\"-data-test-small.pickle\"\n",
    "    train, test   = SeqData(trainf), SeqData(validf)\n",
    "    \n",
    "    # classType = NavigationTask if s == 'navigation' else TransportTask\n",
    "    print(train.env.stateSubVectors)\n",
    "    print('Defining Model')\n",
    "    # Parameters\n",
    "    learning_rate = 0.0005\n",
    "    training_steps = 15000 #2000 # 10000\n",
    "    batch_size = 64 #256 #128\n",
    "    display_step = 200\n",
    "    # Network Parameters\n",
    "    n_hidden = 200 #128 #5*train.lenOfInput # hidden layer num of features\n",
    "    len_state = train.lenOfState # linear sequence or not\n",
    "    len_input = train.lenOfInput\n",
    "    env = NavigationTask()\n",
    "    print('Initializing FM')\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        print('Entering with block')\n",
    "        fm=ForwardModelSoftmax(len_state,len_input, env, batch_size,n_hidden)\n",
    "        print('FM initialized')\n",
    "        fm.train(train,test,training_steps,batch_size,train.env,learning_rate,display_step,\"trained_model_4_noise_0_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n",
      "5\n",
      "Defining Model\n",
      "Initializing FM\n",
      "Entering with block\n",
      "Building Graph\n",
      "Slicing\n",
      "Sliced\n",
      "FM initialized\n",
      "Entering loss func\n",
      "Defining optimizer\n",
      "Running TF initializer\n",
      "Entering train loop\n",
      "Step 64, Minibatch Loss= 0.069836, Training Accuracy= 0.14688\n",
      "Step 12800, Minibatch Loss= 0.043710, Training Accuracy= 0.66563\n",
      "Step 25600, Minibatch Loss= 0.023637, Training Accuracy= 0.83438\n",
      "Step 38400, Minibatch Loss= 0.015723, Training Accuracy= 0.89688\n",
      "Step 51200, Minibatch Loss= 0.016640, Training Accuracy= 0.88438\n",
      "Step 64000, Minibatch Loss= 0.012688, Training Accuracy= 0.90625\n",
      "Step 76800, Minibatch Loss= 0.011508, Training Accuracy= 0.91563\n",
      "Step 89600, Minibatch Loss= 0.012687, Training Accuracy= 0.90938\n",
      "Step 102400, Minibatch Loss= 0.011830, Training Accuracy= 0.91250\n",
      "Step 115200, Minibatch Loss= 0.010728, Training Accuracy= 0.92188\n",
      "Step 128000, Minibatch Loss= 0.010870, Training Accuracy= 0.91875\n",
      "Step 140800, Minibatch Loss= 0.011236, Training Accuracy= 0.90938\n",
      "Step 153600, Minibatch Loss= 0.009985, Training Accuracy= 0.93437\n",
      "Step 166400, Minibatch Loss= 0.011039, Training Accuracy= 0.91875\n",
      "Step 179200, Minibatch Loss= 0.010275, Training Accuracy= 0.92500\n",
      "Step 192000, Minibatch Loss= 0.012814, Training Accuracy= 0.90625\n",
      "Step 204800, Minibatch Loss= 0.008857, Training Accuracy= 0.93125\n",
      "Step 217600, Minibatch Loss= 0.010832, Training Accuracy= 0.91250\n",
      "Step 230400, Minibatch Loss= 0.011043, Training Accuracy= 0.91563\n",
      "Step 243200, Minibatch Loss= 0.011164, Training Accuracy= 0.91563\n",
      "Step 256000, Minibatch Loss= 0.009366, Training Accuracy= 0.92188\n",
      "Step 268800, Minibatch Loss= 0.008981, Training Accuracy= 0.93437\n",
      "Step 281600, Minibatch Loss= 0.011417, Training Accuracy= 0.90000\n",
      "Step 294400, Minibatch Loss= 0.008435, Training Accuracy= 0.93437\n",
      "Step 307200, Minibatch Loss= 0.009227, Training Accuracy= 0.92813\n",
      "Step 320000, Minibatch Loss= 0.007595, Training Accuracy= 0.93750\n",
      "Step 332800, Minibatch Loss= 0.008147, Training Accuracy= 0.93750\n",
      "Step 345600, Minibatch Loss= 0.010861, Training Accuracy= 0.91250\n",
      "Step 358400, Minibatch Loss= 0.008568, Training Accuracy= 0.93125\n",
      "Step 371200, Minibatch Loss= 0.010540, Training Accuracy= 0.92188\n",
      "Step 384000, Minibatch Loss= 0.008597, Training Accuracy= 0.93437\n",
      "Step 396800, Minibatch Loss= 0.011505, Training Accuracy= 0.90625\n",
      "Step 409600, Minibatch Loss= 0.008791, Training Accuracy= 0.92813\n",
      "Step 422400, Minibatch Loss= 0.011798, Training Accuracy= 0.90000\n",
      "Step 435200, Minibatch Loss= 0.009472, Training Accuracy= 0.92813\n",
      "Step 448000, Minibatch Loss= 0.008246, Training Accuracy= 0.93437\n",
      "Step 460800, Minibatch Loss= 0.008472, Training Accuracy= 0.93750\n",
      "Step 473600, Minibatch Loss= 0.010233, Training Accuracy= 0.90938\n",
      "Step 486400, Minibatch Loss= 0.007599, Training Accuracy= 0.94375\n",
      "Step 499200, Minibatch Loss= 0.010329, Training Accuracy= 0.90625\n",
      "Step 512000, Minibatch Loss= 0.013227, Training Accuracy= 0.89375\n",
      "Step 524800, Minibatch Loss= 0.009210, Training Accuracy= 0.92813\n",
      "Step 537600, Minibatch Loss= 0.007682, Training Accuracy= 0.93750\n",
      "Step 550400, Minibatch Loss= 0.008849, Training Accuracy= 0.93437\n",
      "Step 563200, Minibatch Loss= 0.008414, Training Accuracy= 0.93437\n",
      "Step 576000, Minibatch Loss= 0.007540, Training Accuracy= 0.93750\n",
      "Step 588800, Minibatch Loss= 0.010610, Training Accuracy= 0.90938\n",
      "Step 601600, Minibatch Loss= 0.009685, Training Accuracy= 0.91875\n",
      "Step 614400, Minibatch Loss= 0.011066, Training Accuracy= 0.90625\n",
      "Step 627200, Minibatch Loss= 0.009075, Training Accuracy= 0.92500\n",
      "Step 640000, Minibatch Loss= 0.011721, Training Accuracy= 0.90312\n",
      "Step 652800, Minibatch Loss= 0.009205, Training Accuracy= 0.93125\n",
      "Step 665600, Minibatch Loss= 0.005323, Training Accuracy= 0.95625\n",
      "Step 678400, Minibatch Loss= 0.006257, Training Accuracy= 0.94688\n",
      "Step 691200, Minibatch Loss= 0.006528, Training Accuracy= 0.95000\n",
      "Step 704000, Minibatch Loss= 0.007673, Training Accuracy= 0.93750\n",
      "Step 716800, Minibatch Loss= 0.007437, Training Accuracy= 0.94375\n",
      "Step 729600, Minibatch Loss= 0.008079, Training Accuracy= 0.92813\n",
      "Step 742400, Minibatch Loss= 0.009584, Training Accuracy= 0.92188\n",
      "Step 755200, Minibatch Loss= 0.009220, Training Accuracy= 0.92813\n",
      "Step 768000, Minibatch Loss= 0.006924, Training Accuracy= 0.94688\n",
      "Step 780800, Minibatch Loss= 0.007769, Training Accuracy= 0.93750\n",
      "Step 793600, Minibatch Loss= 0.009365, Training Accuracy= 0.92500\n",
      "Step 806400, Minibatch Loss= 0.008193, Training Accuracy= 0.93437\n",
      "Step 819200, Minibatch Loss= 0.009425, Training Accuracy= 0.92188\n",
      "Step 832000, Minibatch Loss= 0.008649, Training Accuracy= 0.92813\n",
      "Step 844800, Minibatch Loss= 0.009966, Training Accuracy= 0.92813\n",
      "Step 857600, Minibatch Loss= 0.008653, Training Accuracy= 0.92813\n",
      "Step 870400, Minibatch Loss= 0.008390, Training Accuracy= 0.92813\n",
      "Step 883200, Minibatch Loss= 0.008964, Training Accuracy= 0.92500\n",
      "Step 896000, Minibatch Loss= 0.009417, Training Accuracy= 0.91250\n",
      "Step 908800, Minibatch Loss= 0.009798, Training Accuracy= 0.91875\n",
      "Step 921600, Minibatch Loss= 0.007885, Training Accuracy= 0.93437\n",
      "Step 934400, Minibatch Loss= 0.008170, Training Accuracy= 0.93437\n",
      "Step 947200, Minibatch Loss= 0.007026, Training Accuracy= 0.94063\n",
      "Step 960000, Minibatch Loss= 0.009288, Training Accuracy= 0.92500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.946875\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "main4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = NavigationTask() \n",
    "state_i = env.getStateRep()\n",
    "predVecs = env.deconcatenateOneHotStateVector(state_i)\n",
    "target = np.zeros(len(state_i))\n",
    "index = 0\n",
    "for pv in predVecs: \n",
    "    target[index:index+len(pv)] = pv\n",
    "    index = index+len(pv)\n",
    "# print(len(target))\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
