{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random as npr, random as r\n",
    "import tensorflow as tf  \n",
    "from NavTask import NavigationTask\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.slim as slim\n",
    "from forwardModel3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Node --> Children  \n",
    "\n",
    "# From: https://github.com/ericjang/gumbel-softmax\n",
    "class GumbelSoftmax(object):\n",
    "    def sample_gumbel(shape, eps=1e-20): \n",
    "      \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "      \"\"\"  dd \"\"\"\n",
    "      U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "      return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(logits, temperature): \n",
    "      \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "      y = logits + GumbelSoftmax.sample_gumbel(tf.shape(logits))\n",
    "      return tf.nn.softmax( y / temperature)\n",
    "\n",
    "    def gumbel_softmax(logits, temperature, hard=False):\n",
    "      \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "      Args:\n",
    "        logits: [batch_size, n_class] unnormalized log-probs\n",
    "        temperature: non-negative scalar\n",
    "        hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "      Returns:\n",
    "        [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "        If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "        be a probabilitiy distribution that sums to 1 across classes\n",
    "      \"\"\"\n",
    "      y = GumbelSoftmax.gumbel_softmax_sample(logits, temperature)\n",
    "      if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "      return y\n",
    "\n",
    "#sess = tf.Session()\n",
    "#sess.run(GumbelSoftmax.gumbel_softmax(tf.constant([[0.5, 0.5]]), 0.5, hard=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimulationPolicy(object):\n",
    "    \n",
    "    def __init__(self, obs_space, act_space, h_size=100):\n",
    "        print(\"Observation Space: \" , obs_space)\n",
    "        print(\"Action Space: \", act_space)\n",
    "        self.h_size = h_size\n",
    "        # Input space: [Episode_length, observations], output:[Episode_Length,action_space]\n",
    "        self.input = tf.placeholder(tf.float32, [None] + list(obs_space))\n",
    "        self.act_space = act_space\n",
    "        #self.output = self.getSoftAction(self.input)\n",
    "        self.sampleOutput = self.sample(self.input)\n",
    "        self.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"softaction\")#tf.get_variable_scope().name) \n",
    "    \n",
    "    def getSoftAction(self,observation, reuse=None):\n",
    "        with tf.variable_scope(\"softaction\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(observation, self.h_size, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            return slim.fully_connected(hidden, self.act_space, activation_fn=tf.nn.softmax, biases_initializer=None)\n",
    "        \n",
    "    def sample(self,observation,temperature=0.5, reuse=None):\n",
    "        sess = tf.get_default_session()\n",
    "        #print(sess.run(tf.report_uninitialized_variables()))\n",
    "        softAction = self.getSoftAction(observation, reuse=reuse)\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        return GumbelSoftmax.gumbel_softmax(softAction, temperature, hard=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-f472e804f3d8>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-f472e804f3d8>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    x, _ = sess.run([sample)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    simpolicy = SimulationPolicy( np.shape([1,1]),3)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample = simpolicy.sample(tf.constant([[5.0,1.0]]), reuse=True) \n",
    "    #sample1 = simpolicy.sample(tf.constant([[5.0,1.0]]), reuse=True)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    x, _ = sess.run([sample)\n",
    "    #writer.close()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, parent_node, state, action):\n",
    "        self.parent = parent_node\n",
    "        self.children = []\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        \n",
    "    def addChild(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self,initialState,forwardModel,simPolicy,maxDepth=5,branchingFactor=3):\n",
    "        self.simPolicy = simPolicy\n",
    "        self.maxDepth, self.branchFactor = maxDepth, branchingFactor\n",
    "        self.forwardModel = forwardModel\n",
    "        parent = Node(None,initialState,None)\n",
    "        # Generate Tree\n",
    "        self.tree_head = self.grow(parent,0,self.branchFactor)\n",
    "        # Get leaves\n",
    "        q, self.leaves = [ parent ], []\n",
    "        while len(q) >= 1:\n",
    "            currNode = q.pop()\n",
    "            for child in currNode.children:\n",
    "                if len( child.children ) == 0: self.leaves.append( child )\n",
    "                else: q.append( child )\n",
    "        print(self.leaves)\n",
    "        \n",
    "    def grow(node,d,b):\n",
    "        if d == self.maxDepth : return node\n",
    "        for i in range(b):\n",
    "            # Sample the current action\n",
    "            a_s = self.simPolicy.sample(node.state)\n",
    "            # Compute the predicted forward state\n",
    "            concat_vec = tf.concat([tf.cast(node.state,dtype=tf.float32),a_s], axis=0)\n",
    "            concat_vec = tf.reshape(concat_vec,[1,1,-1]) #[batch size, sequence length, size of concat_vec]\n",
    "            state_out = self.forwardModel.get_initial_features(1)\n",
    "            current_state,state_out = self.forwardModel.dynamic_cell(concat_vec, tf.constant([1]), state_out)\n",
    "            # Build the next subtree\n",
    "            node.addChild( grow( Node(node, current_state, a_s), d+1, b) )\n",
    "            return node\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.] [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "INFO:tensorflow:Restoring parameters from abcd.ckpt\n",
      "Observation Space:  (64,)\n",
      "Action Space:  10\n",
      "[array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)]\n",
      "Concat Tensor(\"Reshape:0\", shape=(1, 1, 74), dtype=float32)\n",
      "[ 14.53238106   5.99992704   2.20019317   2.8630681    4.68508768\n",
      "   3.92970443   1.04677474  -0.21074444  -3.06503892  -4.37409401\n",
      "  -1.69974387  -0.39283228  -4.58955431  -2.44132566  -8.18487072\n",
      "   1.32199025  -3.81950307  -1.42089391  -0.32325405   4.30451107\n",
      "  -3.14704919   0.99745297  -0.9193486    1.55969918  -4.08195686\n",
      "  -0.09344815  -1.6779151   -0.10107774  -2.44707561   2.35568428\n",
      "   7.28716135  -4.63874817   3.4732821    0.41545379  -1.95708263\n",
      "  -1.23285961  -7.22155905  -5.10941172  -3.56391048  -4.41307163\n",
      "  -2.95476413  -1.84455585  -3.69923687  -0.82782626  -2.61997461\n",
      "  -4.91397285  -2.15747523  -4.36433125   9.73653984  -3.1065805\n",
      "  -6.49898767  -4.61365652  -6.83783817  -5.24279404  -4.33075905\n",
      "  -4.2670846   -4.45408154  -0.88957059  -3.02499866  -7.10562515\n",
      "  -7.60276222  -5.09957314  -3.7993114    8.66259193]\n",
      "0\n",
      "4\n",
      "0\n",
      "14\n",
      "14\n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "env = NavigationTask() \n",
    "state_i=env.getStateRep()\n",
    "observation_space = np.shape(state_i)\n",
    "#get goal state\n",
    "state_f=env.getStateRep()\n",
    "inds = np.cumsum([0,env.w,env.h,len(env.oriens),env.w,env.h])\n",
    "state_f[inds[0]:inds[1]] = env._intToOneHot(env.goal_pos[0],env.w)\n",
    "state_f[inds[1]:inds[2]] = env._intToOneHot(env.goal_pos[1],env.h)\n",
    "num_of_actions = 10\n",
    "print(state_i, state_f)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    forwardModel=ForwardModel(64,74,10, 100)\n",
    "    forwardModel.load_model('abcd.ckpt')\n",
    "    simpolicy = SimulationPolicy( observation_space ,num_of_actions)\n",
    "    reshape_state = np.reshape(state_i,(1,-1))\n",
    "    sess.run(tf.variables_initializer(simpolicy.trainable_vars))\n",
    "    a_s = sess.run([simpolicy.sampleOutput], {simpolicy.input: reshape_state})\n",
    "    #a_s = [[0.,0.,1.,0,0,0,0,0,0,0]]\n",
    "    \n",
    "    print(a_s)\n",
    "    concat_vec = tf.concat([tf.cast(state_i,dtype=tf.float32),tf.squeeze(a_s[0])], axis=0)\n",
    "    concat_vec = tf.reshape(concat_vec,[1,1,-1]) #[batch size, sequence length, size of concat_vec]\n",
    "    print(\"Concat\", concat_vec)\n",
    "    state_out = forwardModel.get_initial_features(1)\n",
    "    current_state,state_out = forwardModel.dynamic_cell(concat_vec, tf.constant([1]), state_out, reuse=True)\n",
    "    output = sess.run([current_state])[0][0]\n",
    "    print(output)\n",
    "    print(np.argmax(output[0:15]))\n",
    "    print(np.argmax(output[15:30]))\n",
    "    print(np.argmax(output[30:34]))\n",
    "    print(np.argmax(output[34:49]))\n",
    "    print(np.argmax(output[49:64]))\n",
    "    \n",
    "    print(np.argmax(state_i[0:15]))\n",
    "    print(np.argmax(state_i[15:30]))\n",
    "    print(np.argmax(state_i[30:34]))\n",
    "    print(np.argmax(state_i[34:49]))\n",
    "    print(np.argmax(state_i[49:64]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
