{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random as npr, random as r\n",
    "import tensorflow as tf  \n",
    "from NavTask import NavigationTask\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.slim as slim\n",
    "from forwardModel3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Node --> Children  \n",
    "\n",
    "# From: https://github.com/ericjang/gumbel-softmax\n",
    "class GumbelSoftmax(object):\n",
    "    def sample_gumbel(shape, eps=1e-20): \n",
    "      \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "      \"\"\"  dd \"\"\"\n",
    "      U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "      return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "    def gumbel_softmax_sample(logits, temperature): \n",
    "      \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "      y = logits + GumbelSoftmax.sample_gumbel(tf.shape(logits))\n",
    "      return tf.nn.softmax( y / temperature)\n",
    "\n",
    "    def gumbel_softmax(logits, temperature, hard=False):\n",
    "      \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "      Args:\n",
    "        logits: [batch_size, n_class] unnormalized log-probs\n",
    "        temperature: non-negative scalar\n",
    "        hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "      Returns:\n",
    "        [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "        If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "        be a probabilitiy distribution that sums to 1 across classes\n",
    "      \"\"\"\n",
    "      y = GumbelSoftmax.gumbel_softmax_sample(logits, temperature)\n",
    "      if hard:\n",
    "        k = tf.shape(logits)[-1]\n",
    "        #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "        y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "      return y\n",
    "\n",
    "#sess = tf.Session()\n",
    "#sess.run(GumbelSoftmax.gumbel_softmax(tf.constant([[0.5, 0.5]]), 0.5, hard=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimulationPolicy(object):\n",
    "    \n",
    "    def __init__(self, obs_space, act_space, h_size=100):\n",
    "        print(\"Observation Space: \" , obs_space)\n",
    "        print(\"Action Space: \", act_space)\n",
    "        self.h_size = h_size\n",
    "        # Input space: [Episode_length, observations], output:[Episode_Length,action_space]\n",
    "        self.input = tf.placeholder(tf.float32, [None] + list(obs_space))\n",
    "        self.act_space = act_space\n",
    "        #self.output = self.getSoftAction(self.input)\n",
    "        self.sampleOutput = self.sample(self.input)\n",
    "        self.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, tf.get_variable_scope().name) \n",
    "    \n",
    "    def getSoftAction(self,observation, reuse=None):\n",
    "        with tf.variable_scope(\"softaction\", reuse=reuse):\n",
    "            hidden = slim.fully_connected(observation, self.h_size, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "            return slim.fully_connected(hidden, self.act_space, activation_fn=tf.nn.softmax, biases_initializer=None)\n",
    "        \n",
    "    def sample(self,observation,temperature=0.5, reuse=None):\n",
    "        sess = tf.get_default_session()\n",
    "        #print(sess.run(tf.report_uninitialized_variables()))\n",
    "        softAction = self.getSoftAction(observation, reuse=reuse)\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        return GumbelSoftmax.gumbel_softmax(softAction, temperature, hard=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space:  (2,)\n",
      "Action Space:  3\n",
      "[[ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    simpolicy = SimulationPolicy( np.shape([1,1]),3)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sample = simpolicy.sample(tf.constant([[5.0,1.0]]), reuse=True) \n",
    "    #sample1 = simpolicy.sample(tf.constant([[5.0,1.0]]), reuse=True)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    x, _ = sess.run([sample)\n",
    "    #writer.close()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, parent_node, state, action):\n",
    "        self.parent = parent_node\n",
    "        self.children = []\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        \n",
    "    def addChild(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self,initialState,forwardModel,simPolicy,maxDepth=5,branchingFactor=3):\n",
    "        self.simPolicy = simPolicy\n",
    "        self.maxDepth, self.branchFactor = maxDepth, branchingFactor\n",
    "        self.forwardModel = forwardModel\n",
    "        parent = Node(None,initialState,None)\n",
    "        # Generate Tree\n",
    "        self.tree_head = self.grow(parent,0,self.branchFactor)\n",
    "        # Get leaves\n",
    "        q, self.leaves = [ parent ], []\n",
    "        while len(q) >= 1:\n",
    "            currNode = q.pop()\n",
    "            for child in currNode.children:\n",
    "                if len( child.children ) == 0: self.leaves.append( child )\n",
    "                else: q.append( child )\n",
    "        print(self.leaves)\n",
    "        \n",
    "    def grow(node,d,b):\n",
    "        if d == self.maxDepth : return node\n",
    "        for i in range(b):\n",
    "            # Sample the current action\n",
    "            a_s = self.simPolicy.sample(node.state)\n",
    "            # Compute the predicted forward state\n",
    "            concat_vec = tf.concat([tf.cast(node.state,dtype=tf.float32),a_s], axis=0)\n",
    "            concat_vec = tf.reshape(concat_vec,[1,1,-1]) #[batch size, sequence length, size of concat_vec]\n",
    "            state_out = self.forwardModel.get_initial_features(1)\n",
    "            current_state,state_out = self.forwardModel.dynamic_cell(concat_vec, tf.constant([1]), state_out)\n",
    "            # Build the next subtree\n",
    "            node.addChild( grow( Node(node, current_state, a_s), d+1, b) )\n",
    "            return node\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.] [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "INFO:tensorflow:Restoring parameters from abcd.ckpt\n",
      "Observation Space:  (64,)\n",
      "Action Space:  10\n",
      "[array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)]\n",
      "[-2.03846502 -0.85695219 -0.51081717 -1.80624509 -1.36497927  0.55826956\n",
      " -1.94655108 -0.51467937 -0.2117053   0.13349709  0.72574234  0.02418317\n",
      " -0.29246455 -0.19109452 -0.53288925 -0.76872003  1.33117223  1.5037179\n",
      " -0.31478378 -1.63553715 -2.1405561   0.34129989 -0.10810138  1.10110307\n",
      "  0.5648883  -0.21380992 -0.69358206 -1.25628376  0.0937382   0.06163095\n",
      " -3.15767789  0.34343553  0.89869559  0.13394481  0.84582204 -1.68512464\n",
      " -0.07535081  0.25003478 -0.95627308 -0.64517599 -0.26556048 -0.02496839\n",
      " -0.32965404  2.9024992   1.03795016 -0.82596761  0.09761223  0.45078725\n",
      "  2.03351808 -0.75855762  0.96992856 -0.80446351  1.10457027 -1.65523469\n",
      "  1.23459148 -0.87347364 -0.61462492  0.91787726  0.35320532 -0.64802819\n",
      "  1.11451995  1.2260747  -0.22253694 -1.50394118]\n",
      "10\n",
      "2\n",
      "2\n",
      "9\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "env = NavigationTask() \n",
    "state_i=env.getStateRep()\n",
    "observation_space = np.shape(state_i)\n",
    "#get goal state\n",
    "state_f=env.getStateRep()\n",
    "inds = np.cumsum([0,env.w,env.h,len(env.oriens),env.w,env.h])\n",
    "state_f[inds[0]:inds[1]] = env._intToOneHot(env.goal_pos[0],env.w)\n",
    "state_f[inds[1]:inds[2]] = env._intToOneHot(env.goal_pos[1],env.h)\n",
    "num_of_actions = 10\n",
    "print(state_i, state_f)\n",
    "\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    forwardModel=ForwardModel(64,74,10, 100)\n",
    "    forwardModel.load_model('abcd.ckpt')\n",
    "    simpolicy = SimulationPolicy( observation_space ,num_of_actions)\n",
    "    reshape_state = np.reshape(state_i,(1,-1))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    a_s = sess.run([simpolicy.sampleOutput], {simpolicy.input: reshape_state})\n",
    "    print(a_s)\n",
    "    concat_vec = tf.concat([tf.cast(state_i,dtype=tf.float32),tf.squeeze(a_s[0])], axis=0)\n",
    "    concat_vec = tf.reshape(concat_vec,[1,1,-1]) #[batch size, sequence length, size of concat_vec]\n",
    "    state_out = forwardModel.get_initial_features(1)\n",
    "    current_state,state_out = forwardModel.dynamic_cell(concat_vec, tf.constant([1]), state_out)\n",
    "    output = sess.run([current_state])[0][0]\n",
    "    print(output)\n",
    "    print(np.argmax(output[0:15]))\n",
    "    print(np.argmax(output[15:30]))\n",
    "    print(np.argmax(output[30:34]))\n",
    "    print(np.argmax(output[34:49]))\n",
    "    print(np.argmax(output[49:64]))\n",
    "    \n",
    "    print(np.argmax(state_i[0:15]))\n",
    "    print(np.argmax(state_i[15:30]))\n",
    "    print(np.argmax(state_i[30:34]))\n",
    "    print(np.argmax(state_i[34:49]))\n",
    "    print(np.argmax(state_i[49:64]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
