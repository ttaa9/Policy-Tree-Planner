{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleFM import *\n",
    "from SimpleTask import SimpleGridTask\n",
    "import numpy as np, numpy.random as npr, random as r, SimpleTask\n",
    "from TransportTask import TransportTask\n",
    "from NavTask import NavigationTask\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Henaff_Planning():\n",
    "    def __init__(self,num_actions,len_action, len_state, iterations, gamma):\n",
    "        self.initialize_forward_model()\n",
    "        self.x= tf.Variable(tf.random_normal([num_actions,len_action])*0.1,name='x', dtype=tf.float32)\n",
    "        self.s_0= tf.placeholder(tf.float32, [len_state])\n",
    "        self.s_f= tf.placeholder(tf.float32, [len_state])\n",
    "        self.iterations=iterations\n",
    "        self.num_actions = num_actions\n",
    "        self.len_action = len_action\n",
    "        self.len_state = len_state\n",
    "        self.gamma=gamma\n",
    "        self.lr_interval=[0.5,0.5]\n",
    "        self.eps=tf.constant(0.00001,shape=[self.num_actions,self.len_action])\n",
    "        self.trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"x\")\n",
    "        \n",
    "    def initialize_forward_model(self):\n",
    "        #sess = tf.get_default_session()\n",
    "        self.fm=ForwardModel(64,74,10, 100)\n",
    "        self.fm.load_model('abcd.ckpt')\n",
    "        \n",
    "    def optimize(self ,init_state,final_state, env):\n",
    "        sess = tf.get_default_session()\n",
    "        for i in range(0,self.iterations):\n",
    "            lr=self.lr_interval[1]-i*((self.lr_interval[1]-self.lr_interval[0])/self.iterations)\n",
    "            print('learning rate: ',lr)\n",
    "\n",
    "            epsilon=tf.random_normal([self.num_actions,self.len_action])*self.gamma\n",
    "            self.x=self.x+epsilon\n",
    "            self.a=tf.nn.softmax(self.x)\n",
    "    \n",
    "            current_state=self.s_0\n",
    "            state_out = self.fm.get_initial_features(1)\n",
    "            for t in range(0,self.num_actions):\n",
    "                \n",
    "                #print(t)\n",
    "                current_state=tf.reshape(current_state,[64,])\n",
    "                concat_vec = tf.concat([tf.cast(current_state,dtype=tf.float32),self.a[t]],axis=0)\n",
    "                concat_vec=tf.reshape(concat_vec,[1,1,-1]) #[batch size, sequence length, size of concat_vec]\n",
    "                \n",
    "                current_state,state_out = self.fm.dynamic_cell(concat_vec,tf.constant([1]), state_out)\n",
    "                c, h = state_out\n",
    "                state_out= tf.nn.rnn_cell.LSTMStateTuple(c, h)\n",
    "        \n",
    "            \n",
    "            current_state=tf.reshape(current_state,[64,-1])\n",
    "            predVecs = env.deconcatenateOneHotStateVector(current_state)\n",
    "            labelVecs = env.deconcatenateOneHotStateVector(self.s_f)\n",
    "          \n",
    "            loss=0\n",
    "            for pv,lv in zip(predVecs,labelVecs):\n",
    "                loss += tf.nn.softmax_cross_entropy_with_logits(logits=tf.transpose(pv), labels=lv)\n",
    "\n",
    "            print(\"Iteration: ####################################### \", i)\n",
    "            print(tf.global_variables())\n",
    "\n",
    "            self.gradients = tf.gradients(loss, [self.x])\n",
    "            print(self.gradients)\n",
    "            self.x = self.x - tf.multiply(self.gradients[0], lr) \n",
    "            \n",
    "            print(\"grad\",tf.report_uninitialized_variables())\n",
    "#             if i == 0:\n",
    "#                 init_new_vars_op = tf.initialize_all_variables()\n",
    "#                 sess.run(init_new_vars_op)\n",
    "            loss, value_x, s_curr= sess.run([loss, self.x, current_state],{self.s_0:init_state,self.s_f:final_state})\n",
    "            print(loss)            \n",
    "            for xi in value_x:\n",
    "                print(NavigationTask.actions[np.argmax(xi)])\n",
    "            print(loss)\n",
    "            scurrv = env.deconcatenateOneHotStateVector(s_curr)\n",
    "            print('px:',np.argmax(scurrv[0]))\n",
    "            print('py:',np.argmax(scurrv[1]))\n",
    "            print('d:',np.argmax(scurrv[2]))\n",
    "            print('gx:',np.argmax(scurrv[3]))\n",
    "            print('gy:',np.argmax(scurrv[4]))\n",
    "            \n",
    "            #             print(s_curr)\n",
    "            \n",
    "#             print(self.s_f)\n",
    "#             #print(s_curr.shape)\n",
    "#             print(self.s_f.shape)\n",
    "#             print('--')\n",
    "\n",
    "\n",
    "\n",
    "        return value_x\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    hp = Henaff_Planning(10,10,64,30,0.1)\n",
    "    #hp.optimize()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from abcd.ckpt\n"
     ]
    }
   ],
   "source": [
    "def navmain():\n",
    "\n",
    "    \n",
    "    env = NavigationTask() #(stochasticity=0.2)\n",
    "    \n",
    "\n",
    "    state_i=env.getStateRep()\n",
    "\n",
    "    #get goal state\n",
    "    state_f=env.getStateRep()\n",
    "    inds = np.cumsum([0,env.w,env.h,len(env.oriens),env.w,env.h])\n",
    "    state_f[inds[0]:inds[1]] = env._intToOneHot(env.goal_pos[0],env.w)\n",
    "    state_f[inds[1]:inds[2]] = env._intToOneHot(env.goal_pos[1],env.h)\n",
    "\n",
    "    state_i=env.getStateRep() #get initial state\n",
    "    \n",
    "    #we want the goal state so replce the first position vector with the goal position vector\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        hp = Henaff_Planning(10,10,64,20,0.0000001)#initialize hennaff planning method\n",
    "        init = tf.variables_initializer(hp.trainable_vars)\n",
    "        sess.run(init)\n",
    "        print(state_i,state_f)\n",
    "        action_sequence=hp.optimize(state_i,state_f,env)\n",
    "\n",
    "    #convert action sequence to [num_action,] action numer ids\n",
    "    action_sequence=np.argmax(action_sequence,1)\n",
    "    action_sequence=np.reshape(action_sequence,[len(action_sequence),])\n",
    "\n",
    "    for action in action_sequence:\n",
    "        print('\\n')\n",
    "        print('-Initial State-')\n",
    "        env.display()\n",
    "        print('-Action Taken-')\n",
    "        env.performAction(action)\n",
    "        print(env.actions[action])\n",
    "        print('-Resultant State-')\n",
    "        env.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n",
      "--------\n",
      "6\n",
      "(74,)\n",
      "INFO:tensorflow:Restoring parameters from abcd.ckpt\n",
      "0\n",
      "0\n",
      "0\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    env = NavigationTask() #(stochasticity=0.2)\n",
    "    state_i=env.getStateRep()\n",
    "    #reshape_state = np.reshape(state_i, [1,64])\n",
    "    print(np.argmax(state_i[0:15]))\n",
    "    print(np.argmax(state_i[15:30]))\n",
    "    print(np.argmax(state_i[30:34]))\n",
    "    print(np.argmax(state_i[34:49]))\n",
    "    print(np.argmax(state_i[49:64]))\n",
    "    print(\"--------\")\n",
    "    a_s = [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0. , 0.,  0.]\n",
    "    print(np.argmax(a_s[0:15]))\n",
    "    input_value =  np.concatenate((state_i, a_s))\n",
    "    print(input_value.shape)\n",
    "    input_value = np.reshape(input_value, [1,74]).astype(np.float32)\n",
    "    fm=ForwardModel(64,74,200)\n",
    "    fm.load_model('abcd.ckpt')\n",
    "    result = fm.build_graph(input_value, reuse=True)\n",
    "    result = sess.run(result)\n",
    "    #print(sess.run(result))\n",
    "    \n",
    "    print(np.argmax(result[0][0:15]))\n",
    "    print(np.argmax(result[0][15:30]))\n",
    "    print(np.argmax(result[0][30:34]))\n",
    "    print(np.argmax(result[0][34:49]))\n",
    "    print(np.argmax(result[0][49:64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n"
     ]
    }
   ],
   "source": [
    "s = 'navigation' #'navigation'\n",
    "trainf, validf = s+\"-data-train-small.pickle\", s+\"-data-test-small.pickle\"\n",
    "train, test   = SeqData(trainf), SeqData(validf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74,)\n",
      "7\n",
      "5\n",
      "3\n",
      "14\n",
      "12\n",
      "-----------\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "-----------\n",
      "5\n",
      "5\n",
      "3\n",
      "14\n",
      "12\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "result, valuey= train.next_batch_nonseq(1)\n",
    "print(result[0].shape)\n",
    "print(np.argmax(result[0][0:15]))\n",
    "print(np.argmax(result[0][15:30]))\n",
    "print(np.argmax(result[0][30:34]))\n",
    "print(np.argmax(result[0][34:49]))\n",
    "print(np.argmax(result[0][49:64]))\n",
    "print(\"-----------\")\n",
    "print(result[0][64:74])\n",
    "print(\"-----------\")\n",
    "result =valuey\n",
    "print(np.argmax(result[0][0:15]))\n",
    "print(np.argmax(result[0][15:30]))\n",
    "print(np.argmax(result[0][30:34]))\n",
    "print(np.argmax(result[0][34:49]))\n",
    "print(np.argmax(result[0][49:64]))\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
