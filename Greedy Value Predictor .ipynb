{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.autograd as autograd\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable as avar\n",
    "    \n",
    "from SimpleTask import SimpleGridTask\n",
    "from TransportTask import TransportTask\n",
    "from NavTask import NavigationTask\n",
    "from SeqData import SeqData\n",
    "\n",
    "\n",
    "\n",
    "import os, sys, pickle, numpy as np, numpy.random as npr, random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyValuePredictor(nn.Module):\n",
    "    def __init__(self,  env, layerSizes=[100,100]):\n",
    "        super(GreedyValuePredictor, self).__init__()\n",
    "        self.stateSize = len(env.getStateRep(oneHotOutput=True))\n",
    "        self.env = env\n",
    "        self.rewardSize = 1\n",
    "        print(\"State Size: \" , self.stateSize)        \n",
    "        # Input space: [Batch, observations], output:[Batch, Reward]\n",
    "        self.layer1 = nn.Linear(self.stateSize, layerSizes[0])\n",
    "        self.layer2 = nn.Linear(layerSizes[0], layerSizes[1])\n",
    "        self.layer3 = nn.Linear(layerSizes[1], self.rewardSize)\n",
    "        \n",
    "    def forward(self,state):\n",
    "        output = F.relu( self.layer1(state) )\n",
    "        output = F.relu( self.layer2(output) ) # F.sigmoid\n",
    "        output = self.layer3(output)\n",
    "        #print(output.shape)\n",
    "        m = nn.Sigmoid()\n",
    "        output = m(output)\n",
    "        return output\n",
    "    \n",
    "    def train(self, trainSet, validSet, nEpochs=1500, batch_size=200, validateEvery=200, vbs=500, printEvery=200):\n",
    "        optimizer = optim.Adam(self.parameters(), lr = 0.0003)\n",
    "        state_size = self.stateSize\n",
    "        lossFunction = nn.BCELoss()\n",
    "        \n",
    "        train_x, train_y = trainSet\n",
    "        train_x = avar( torch.FloatTensor(train_x), requires_grad=False)\n",
    "        train_y = avar( torch.FloatTensor(train_y), requires_grad=False)\n",
    "        valid_x, valid_y = validSet \n",
    "        valid_x = avar( torch.FloatTensor(valid_x), requires_grad=False)\n",
    "        valid_y = avar( torch.FloatTensor(valid_y), requires_grad=False)\n",
    "        ntrain, nvalid = len(train_x), len(valid_x)\n",
    "        \n",
    "        def getRandomMiniBatch(dsx,dsy,mbs,nmax):\n",
    "            choices = torch.LongTensor( np.random.choice(nmax, size=mbs, replace=False) )\n",
    "            return dsx[choices], dsy[choices]\n",
    "        for epoch in range(nEpochs):\n",
    "            if epoch % printEvery == 0: print('Epoch:',epoch, end='')\n",
    "            loss = 0.0\n",
    "            self.zero_grad() # Zero out gradients\n",
    "            batch_x, batch_y = getRandomMiniBatch(train_x,train_y,batch_size,ntrain)\n",
    "            prediction = self.forward(batch_x) #[-1,:]\n",
    "            label = batch_y.unsqueeze(dim=1)\n",
    "            #print(label.shape, prediction.shape)\n",
    "            loss = lossFunction(prediction, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % printEvery == 0: print(\" -> AvgLoss\",str(loss.data[0]/ batch_size))\n",
    "            if epoch % validateEvery == 0:\n",
    "                batch_vx, batch_vy = getRandomMiniBatch(valid_x,valid_y,batch_size,nvalid)\n",
    "                predv = self.forward(batch_vx) #[-1,:]\n",
    "                vy = batch_vy.unsqueeze(dim=1)\n",
    "                acc = self._accuracyBatch(vy,predv)\n",
    "                print(\"VACC (noiseless) =\",'%.4f' % acc,end=', ')\n",
    "                print('/n')\n",
    "                \n",
    "    def _accuracyBatch(self,ylist,yhatlist):\n",
    "        n, acc = ylist.data.shape[0], 0.0 \n",
    "        for i in range(n):\n",
    "            acc += self._accuracySingle(ylist[i], yhatlist[i])\n",
    "        return acc / n\n",
    "\n",
    "    # Accuracy averaged over subvecs\n",
    "    def _accuracySingle(self,label,prediction):\n",
    "        #print(label.data[0],prediction.data[0])\n",
    "        if label.data[0] == 1.0:\n",
    "            locAcc = 1.0 if prediction.data[0] > 0.5 else 0.0\n",
    "        else:\n",
    "            locAcc = 1.0 if prediction.data[0] < 0.5 else 0.0\n",
    "        return locAcc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "\tReading navigation-data-state_to_reward-train.pickle\n",
      "\tReading navigation-data-state_to_reward-valid.pickle\n"
     ]
    }
   ],
   "source": [
    "ts = \"navigation-data-state_to_reward-train.pickle\"\n",
    "vs = \"navigation-data-state_to_reward-valid.pickle\"\n",
    "############\n",
    "print('Reading Data')\n",
    "with open(ts,'rb') as inFile:\n",
    "    print('\\tReading',ts); trainSet = pickle.load(inFile)\n",
    "with open(vs,'rb') as inFile:\n",
    "    print('\\tReading',vs); validSet = pickle.load(inFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Size:  64\n"
     ]
    }
   ],
   "source": [
    "env = NavigationTask()\n",
    "greedyvp = GreedyValuePredictor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 -> AvgLoss 0.003300641179084778\n",
      "VACC (noiseless) = 1.0000, /n\n",
      "Epoch: 200 -> AvgLoss 0.0016815374791622163\n",
      "VACC (noiseless) = 0.9900, /n\n",
      "Epoch: 400 -> AvgLoss 0.0015091486275196075\n",
      "VACC (noiseless) = 0.9900, /n\n",
      "Epoch: 600 -> AvgLoss 0.0005108853429555893\n",
      "VACC (noiseless) = 1.0000, /n\n",
      "Epoch: 800 -> AvgLoss 8.769051171839237e-05\n",
      "VACC (noiseless) = 1.0000, /n\n",
      "Epoch: 1000 -> AvgLoss 2.8275982476770877e-05\n",
      "VACC (noiseless) = 1.0000, /n\n",
      "Epoch: 1200 -> AvgLoss 1.6828174702823164e-05\n",
      "VACC (noiseless) = 1.0000, /n\n",
      "Epoch: 1400 -> AvgLoss 8.750113192945718e-06\n",
      "VACC (noiseless) = 1.0000, /n\n"
     ]
    }
   ],
   "source": [
    "greedyvp.train( trainSet, validSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTask(px,py,orien,gx,gy):\n",
    "    direction = NavigationTask.oriens[orien]\n",
    "    gs = np.array([gx, gy])\n",
    "    env = NavigationTask(agent_start_pos=[np.array([px,py]), direction],goal_pos=gs)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.086873e-06]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = generateTask(0,1,2,3,2)\n",
    "state = avar( torch.FloatTensor(env.getStateRep()), requires_grad=False).view(1,-1)\n",
    "print(state.shape)\n",
    "greedyvp.forward(state).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fm.state_dict(), \"greedy_value_predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = trainSet\n",
    "ntrain= len(train_x)\n",
    "x, l = getRandomMiniBatch(train_x,train_y,200,ntrain)\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomMiniBatch(dsx,dsy,mbs,nmax):\n",
    "    choices = torch.LongTensor( np.random.choice(nmax, size=mbs, replace=False) )\n",
    "    return dsx[choices], dsy[choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
