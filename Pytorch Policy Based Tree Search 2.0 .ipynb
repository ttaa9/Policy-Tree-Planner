{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.autograd as autograd\n",
    "import torch.nn as nn, torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable as avar\n",
    "    \n",
    "from SimpleTask import SimpleGridTask\n",
    "from TransportTask import TransportTask\n",
    "from NavTask import NavigationTask\n",
    "from SeqData import SeqData\n",
    "from LSTMFM2 import LSTMForwardModel\n",
    "\n",
    "\n",
    "import os, sys, pickle, numpy as np, numpy.random as npr, random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape) #.cuda()\n",
    "    return -avar(torch.log(-torch.log(U + eps) + eps))\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, temperature):\n",
    "    \"\"\"\n",
    "    input: [*, n_class]\n",
    "    return: [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    return y #+ (y_hard - y).detach() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_valueF(state):\n",
    "    state = state.squeeze()\n",
    "    #ForwardModel.printState(state)\n",
    "    vx = torch.sum((state[0:15]-state[34:49]).pow(2))\n",
    "    #print('vx',vx)\n",
    "    vy = torch.sum((state[15:30]-state[49:64]).pow(2))\n",
    "    #print('vy',vy)\n",
    "    value = -( vx + vy ) \n",
    "    return value\n",
    "\n",
    "def greedy_cont_valueF(state):\n",
    "    state = state.squeeze()\n",
    "    _,ix = state[0:15].max(0)\n",
    "    _,gx = state[34:49].max(0)\n",
    "    _,iy = state[15:30].max(0)\n",
    "    _,gy = state[49:64].max(0)\n",
    "    #ForwardModel.printState(state)\n",
    "    vx = torch.sum((ix - gx)*(ix - gx))\n",
    "    #print('vx',vx)\n",
    "    vy = torch.sum((iy - gy)*(iy - gy))\n",
    "    #print('vy',vy)\n",
    "    value = -( vx + vy ) \n",
    "    return value\n",
    "\n",
    "def greedy_CE(state):\n",
    "    state = state.squeeze()\n",
    "    _, gx = state[34:49].max(0)\n",
    "    _, gy = state[49:64].max(0)\n",
    "    \n",
    "    px = state[0:15]\n",
    "    py = state[15:30]\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    vx = loss(px.unsqueeze(dim=0), gx)\n",
    "    vy  = loss(py.unsqueeze(dim=0), gy)\n",
    "#     print(vx,vy)\n",
    "    return - (vx + vy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data\n",
      "Reading navigation-data-train-small.pickle\n",
      "\tBuilt\n",
      "Reading navigation-data-test-small.pickle\n",
      "\tBuilt\n"
     ]
    }
   ],
   "source": [
    "f_model_name = 'LSTM_FM_1_99' \n",
    "s = 'navigation' # 'transport'\n",
    "trainf, validf = s + \"-data-train-small.pickle\", s + \"-data-test-small.pickle\"\n",
    "print('Reading Data')\n",
    "train, valid = SeqData(trainf), SeqData(validf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTask(px,py,orien,gx,gy):\n",
    "    direction = NavigationTask.oriens[orien]\n",
    "    gs = np.array([gx, gy])\n",
    "    env = NavigationTask(agent_start_pos=[np.array([px,py]), direction],goal_pos=gs)\n",
    "    return env\n",
    "\n",
    "class SimulationPolicy(nn.Module):\n",
    "    def __init__(self,  env, layerSizes=[100,100]):\n",
    "        super(SimulationPolicy, self).__init__()\n",
    "        self.actionSize = len(env.actions)\n",
    "        self.stateSize = len(env.getStateRep(oneHotOutput=True))\n",
    "        self.env = env\n",
    "        print(\"State Size: \" , self.stateSize)\n",
    "        print(\"Action Size: \", self.actionSize)\n",
    "        \n",
    "        # Input space: [Batch, observations], output:[Batch, action_space]\n",
    "        self.layer1 = nn.Linear(self.stateSize, layerSizes[0])\n",
    "        self.layer2 = nn.Linear(layerSizes[0], layerSizes[1])\n",
    "        self.layer3 = nn.Linear(layerSizes[1], self.actionSize)\n",
    "        \n",
    "    def sample(self,state,temperature=2):\n",
    "        output = F.relu( self.layer1(state) )\n",
    "        output = F.relu( self.layer2(output) ) # F.sigmoid\n",
    "        output = self.layer3(output)\n",
    "        #print(output.shape)\n",
    "        soft_output = F.softmax(output, dim=1)\n",
    "        m = nn.LogSoftmax(dim=1)\n",
    "        output = m(output)\n",
    "        return gumbel_softmax(output, temperature), soft_output\n",
    "    \n",
    "    def forward(self, state):\n",
    "        output = F.relu( self.layer1(state) )\n",
    "        output = F.relu( self.layer2(output) ) # F.sigmoid\n",
    "        output = self.layer3(output) \n",
    "        output = F.softmax(output,dim=1)\n",
    "        return output\n",
    "    \n",
    "    def trainSad(self, forwardModel):\n",
    "        \n",
    "        optimizer = optim.Adam(self.parameters(), lr = 0.0005 )\n",
    "\n",
    "        maxDepth = 3\n",
    "        treeBreadth = 2\n",
    "        for p in forwardModel.parameters(): p.requires_grad = False\n",
    "#         p = npr.randint(0,15,2)\n",
    "#         orien = npr.randint(0,4,1)\n",
    "#         g = npr.randint(0,15,2)\n",
    "        cenv = generateTask(0,0,0,0,6)\n",
    "#       cenv = generateTask(p[0],p[1],orien,g[0],g[1])\n",
    "        s0 = avar(torch.FloatTensor([self.env.getStateRep()]), requires_grad=False)\n",
    "        for i in range(0,3000):\n",
    "            tree = Tree(s0,forwardModel,self,greedy_valueF, self.env,maxDepth,treeBreadth)\n",
    "            loss = tree.getLossFromAllNodes()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if i % 200 == 0: print('Loss',i,\":\",loss.data[0])\n",
    "        \n",
    "# POSSIBLE IDEA\n",
    "# Dont just consider the leaves; consider all the nodes as possible leaves (consider all subpaths too)\n",
    "\n",
    "class Node(object):\n",
    "    \n",
    "    def __init__(self, parent_node, state, action, sampledAction, hidden):\n",
    "        self.parent = parent_node\n",
    "        self.children = []\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.sampledAction = sampledAction\n",
    "        self.hidden = hidden\n",
    "        \n",
    "        \n",
    "    def addChild(self, child):\n",
    "        self.children.append(child)\n",
    "        \n",
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self, initialState, forwardModel, simPolicy, valueF, env,maxDepth=5, branchingFactor=3):\n",
    "        self.simPolicy = simPolicy\n",
    "        self.maxDepth, self.branchFactor = maxDepth, branchingFactor\n",
    "        self.forwardModel = forwardModel\n",
    "        self.valueF = valueF\n",
    "        self.allStates = [initialState]\n",
    "        self.allActions = []\n",
    "        self.allNodes = []\n",
    "        self.env = env\n",
    "#         print('Generating growth')\n",
    "        # Generate Tree\n",
    "        self.forwardModel.reInitialize(1)\n",
    "        parent = Node(None,initialState,None, None, self.forwardModel.hidden)\n",
    "        self.allNodes.append(parent)\n",
    "        self.tree_head = self.grow(parent,0,self.branchFactor)\n",
    "        #self.tAllStates = tf.stack(self.allStates)\n",
    "        # Get leaves\n",
    "#         print('Getting leaves')\n",
    "        q, self.leaves = [ parent ], []\n",
    "        while len(q) >= 1:\n",
    "            currNode = q.pop()\n",
    "            for child in currNode.children:\n",
    "                if len( child.children ) == 0: self.leaves.append( child )\n",
    "                else: q.append( child )\n",
    "        #print(self.leaves)\n",
    "        \n",
    "    def getPathFromNode(self,nodeNumber):\n",
    "        node = self.allNodes[nodeNumber]\n",
    "        path = [node.state]\n",
    "        actions = [node.action]\n",
    "        currNode = node\n",
    "        while not currNode.parent is None:\n",
    "            #print(currNode.state)\n",
    "            path.append(currNode.parent.state)\n",
    "            if not currNode.parent.action is None:\n",
    "                actions.append(currNode.parent.action)\n",
    "            currNode = currNode.parent\n",
    "        return (list(reversed(path)),list(reversed(actions)))\n",
    "    \n",
    "    def getPathFromLeaf(self,leafNumber):\n",
    "        leaf = self.leaves[leafNumber]\n",
    "        path = [leaf.state]\n",
    "        actions = [leaf.action]\n",
    "        currNode = leaf\n",
    "        while not currNode.parent is None:\n",
    "            #print(currNode.state)\n",
    "            path.append(currNode.parent.state)\n",
    "            if not currNode.parent.action is None:\n",
    "                actions.append(currNode.parent.action)\n",
    "            currNode = currNode.parent\n",
    "        return (list(reversed(path)),list(reversed(actions)))\n",
    "    \n",
    "    def grow(self,node,d,b,verbose=False):\n",
    "        if verbose: print('Grow depth: ',d)\n",
    "        if verbose: self.env.printState(node.state[0].data.numpy())\n",
    "        if d == self.maxDepth : return node\n",
    "        #print(d)\n",
    "        for i in range(b):\n",
    "            # Sample the current action\n",
    "            hard_action, soft_a_s = self.simPolicy.sample(node.state)\n",
    "            a_s =  [torch.squeeze(hard_action)]\n",
    "            #print(a_s)\n",
    "            #concat_vec = torch.cat([node.state, a_s], 1)\n",
    "            #print(\"concat_vec\",concat_vec.data.numpy(),d)\n",
    "            inital_state =  torch.squeeze(node.state)\n",
    "            #print(inital_state.shape)\n",
    "            #print(a_s[0].shape)\n",
    "            #self.forwardModel.reInitialize(1)\n",
    "            self.forwardModel.setHiddenState(node.hidden)\n",
    "            current_state, _, current_hidden = self.forwardModel.forward(inital_state,a_s, 1)\n",
    "            # Build the next subtre\n",
    "            current_state = current_state.unsqueeze(dim=0)\n",
    "            \n",
    "            self.allStates.append(current_state)\n",
    "            self.allActions.append(a_s)\n",
    "            if verbose: print(\"int_state at depth\",d)\n",
    "            if verbose: self.env.printState(node.state[0].data.numpy())\n",
    "            if verbose: print(\"a_s at depth \",d,\" and breath\",i)\n",
    "            #if verbose: self.env.printAction(a_s[0])\n",
    "            #self.env.printAction(a_s[0])\n",
    "            if verbose: print(\"curr_state at depth\",d)\n",
    "            if verbose: self.env.printState(current_state[0].data.numpy())\n",
    "            childNode = Node(node, current_state, [soft_a_s], [hard_action],current_hidden)\n",
    "            self.allNodes.append( childNode )\n",
    "            node.addChild( self.grow( childNode, d+1, b) )\n",
    "        return node\n",
    "    \n",
    "    # need to call getLossFromAllNodes first\n",
    "    def getBestPlan(self):\n",
    "        bestInd, bestVal = 0, avar(torch.FloatTensor( [float('inf')])) #float('-inf')\n",
    "        for i, node in enumerate(self.allNodes):\n",
    "            currVal = node.loss #self.valueF(leaf.state)\n",
    "            #print('State')\n",
    "            #self.forwardModel.printState(leaf.state[0])\n",
    "            #print('Value',currVal)\n",
    "            if currVal.data.numpy() < bestVal.data.numpy():\n",
    "                bestInd = i\n",
    "                bestVal = currVal\n",
    "        print(\"index\",bestInd)\n",
    "        return self.getPathFromNode( bestInd )\n",
    "    \n",
    "    def getBestPlanByLen(self):\n",
    "        bestInd, bestVal = 0, avar(torch.FloatTensor( [float('inf')])) #float('-inf')\n",
    "        bestPath = None #float('-inf')\n",
    "        for i, node in enumerate(self.allNodes):\n",
    "            currVal = node.loss #self.valueF(leaf.state)\n",
    "            currPath = self.getPathFromNode( bestInd )\n",
    "            currlen = len(currPath)\n",
    "            #print('State')\n",
    "            #self.forwardModel.printState(leaf.state[0])\n",
    "            #print('Value',currVal)\n",
    "            if currVal.data.numpy() <= bestVal.data.numpy(): \n",
    "                if bestPath is None or currlen < len(bestPath):\n",
    "                    bestInd = i\n",
    "                    bestVal = currVal\n",
    "                    bestPath = currPath\n",
    "        print(\"index\",bestInd)\n",
    "        return bestPath\n",
    "    \n",
    "    def getLossFromLeaves(self, lambda_h=1):\n",
    "        totalLosses = avar(torch.FloatTensor([0.0]))\n",
    "        #totalLosses = avar(torch.FloatTensor(len(self.leaves)))\n",
    "        for i, leaf in enumerate(self.leaves):\n",
    "            #totalLosses[i] = -self.valueF( leaf.state )\n",
    "            totalLosses += -self.valueF( leaf.state ) #+ lambda_h * torch.sum(leaf.action[0] * torch.log(leaf.action[0]))\n",
    "            #print(leaf.action[0].data.numpy().argmax(),-self.valueF( leaf.state ).data[0])\n",
    "        return  totalLosses/len(self.leaves) #torch.min(totalLosses)\n",
    "        \n",
    "    # Returns average loss over all nodes\n",
    "    # Also, stores the loss for each node in that node\n",
    "    def getLossFromAllNodes(self):\n",
    "        totalLosses = avar(torch.FloatTensor([0.0]))\n",
    "        nNodes = len(self.allNodes)\n",
    "        for node in self.allNodes:\n",
    "            node.loss = -self.valueF( node.state )\n",
    "            totalLosses += node.loss\n",
    "        return totalLosses / nNodes\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleEnv = generateTask(0,0,0,0,6)\n",
    "ForwardModel = LSTMForwardModel(train.lenOfInput,train.lenOfState)\n",
    "ForwardModel.load_state_dict( torch.load(f_model_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Size:  64\n",
      "Action Size:  10\n",
      "Loss 0 : 1.1083039045333862\n",
      "Loss 200 : 0.800731360912323\n",
      "Loss 400 : 0.726294219493866\n",
      "Loss 600 : 0.626849889755249\n",
      "Loss 800 : 0.6035706996917725\n",
      "Loss 1000 : 0.611242949962616\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-6592c79e0f41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mSimPolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimulationPolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexampleEnv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSimPolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainSad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mForwardModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-188-610b2e8b01e0>\u001b[0m in \u001b[0;36mtrainSad\u001b[1;34m(self, forwardModel)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0ms0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetStateRep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mforwardModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgreedy_valueF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtreeBreadth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLossFromAllNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-188-610b2e8b01e0>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initialState, forwardModel, simPolicy, valueF, env, maxDepth, branchingFactor)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitialState\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwardModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallNodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_head\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranchFactor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;31m#self.tAllStates = tf.stack(self.allStates)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# Get leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-188-610b2e8b01e0>\u001b[0m in \u001b[0;36mgrow\u001b[1;34m(self, node, d, b, verbose)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mchildNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msoft_a_s\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhard_action\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurrent_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallNodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mchildNode\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddChild\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrow\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mchildNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-188-610b2e8b01e0>\u001b[0m in \u001b[0;36mgrow\u001b[1;34m(self, node, d, b, verbose)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[1;31m#self.forwardModel.reInitialize(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwardModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetHiddenState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforwardModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minital_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m             \u001b[1;31m# Build the next subtre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\projects\\final\\final\\final\\Policy-Tree-Planner\\LSTMFM2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, initial_state, actions, seqn)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mconcat_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0moutput_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddenToState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mint_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim_tensor1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdim_tensor2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SimPolicy = SimulationPolicy(exampleEnv)\n",
    "SimPolicy.trainSad(ForwardModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n"
     ]
    }
   ],
   "source": [
    "s_0 = torch.unsqueeze(avar(torch.FloatTensor(exampleEnv.getStateRep())), dim =0)\n",
    "print(s_0.shape)\n",
    "tree = Tree(s_0,ForwardModel,SimPolicy,greedy_valueF,exampleEnv,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-206-6d3b2854ece6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(states)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     print(torch.log(actions[i][0].data))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "tree.getLossFromAllNodes()\n",
    "states, actions = tree.getBestPlanByLen()\n",
    "# for i,node in enumerate(tree.allNodes):\n",
    "#     print(i,'loss',node.loss)\n",
    "# print(states)\n",
    "for i in range(len(actions)):\n",
    "    print(actions[i][0].data.numpy().argmax())\n",
    "    print(actions[i][0].data)\n",
    "#     print(torch.log(actions[i][0].data))\n",
    "    print(gumbel_softmax(torch.log(actions[i][0]), 2))\n",
    "# print(tree.getBestPlan())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n",
      "8\n",
      "2\n",
      "8\n",
      "2\n",
      "2\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tree.leaves)):\n",
    "    states, actions = tree.getPathFromLeaf(i)\n",
    "    for i in range(len(actions)):\n",
    "        print(actions[i][0].data.numpy().argmax())\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model_name = 'forward-ffann-noisy-wan-1.pt' # 6 gets 99% on 0.1% noise\n",
    "exampleEnv = NavigationTask()\n",
    "ForwardModel = ForwardModelFFANN(exampleEnv)\n",
    "ForwardModel.load_state_dict( torch.load(f_model_name) )\n",
    "#ForwardModel.printState(avar(torch.FloatTensor(testEnv.getStateRep()), requires_grad=False))\n",
    "#SimPolicy = SimulationPolicy(exampleEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimPolicy = SimulationPolicy(exampleEnv)\n",
    "SimPolicy.trainSad(ForwardModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testEnv = generateTask(0,0,0,2,3)\n",
    "print(testEnv.getStateRep())\n",
    "s0 = avar(torch.FloatTensor([testEnv.getStateRep()]), requires_grad=False)\n",
    "#greedy_valueF(s0)\n",
    "tree = Tree(s0,ForwardModel,SimPolicy,greedy_cont_valueF,4,5)\n",
    "nodes,actions = tree.getBestPlan()\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Simulation Policy\n",
    "env = NavigationTask() \n",
    "simpolicy = SimulationPolicy(env)\n",
    "simpolicy.sample(avar(torch.FloatTensor([env.getStateRep()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and testing Forward Model\n",
    "f_model_name = 'forward-ffann-noisy-wan-1.pt' # 6 gets 99% on 0.1% noise\n",
    "exampleEnv = NavigationTask()\n",
    "f = ForwardModelFFANN(exampleEnv)\n",
    "f.load_state_dict( torch.load(f_model_name) )\n",
    "start = np.zeros(74, dtype=np.float32)\n",
    "start[0+4] = 1\n",
    "start[15+6] = 1\n",
    "start[15+15+0] = 1\n",
    "start[15+15+4+8] = 1\n",
    "start[15+15+4+15+7] = 1\n",
    "start[15+15+4+15+15+4] = 1.0\n",
    "f.test(start)\n",
    "print('-----\\n','Starting manualTest loop')\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "for i in range(5):\n",
    "    width, height = 15, 15\n",
    "    p_0 = np.array([npr.randint(0,width),npr.randint(0,height)])\n",
    "    start_pos = [p_0, r.choice(NavigationTask.oriens)]\n",
    "    goal_pos = np.array([ npr.randint(0,width), npr.randint(0,height) ])\n",
    "    checkEnv = NavigationTask(\n",
    "        width=width, height=height, agent_start_pos=start_pos, goal_pos=goal_pos,\n",
    "        track_history=True, stochasticity=0.0, maxSteps=10)\n",
    "    s_0 = checkEnv.getStateRep()\n",
    "    #a1, a2 = np.zeros(10), np.zeros(10)\n",
    "    #a1[ npr.randint(0,10) ] = 1\n",
    "    #a2[ npr.randint(0,10) ] = 1\n",
    "    numActions = 3\n",
    "    currState = avar( torch.FloatTensor(s_0).unsqueeze(0) )\n",
    "    print('Start State')\n",
    "    f.printState( currState[0] )\n",
    "    actionSet = []\n",
    "    for j in range(numActions):\n",
    "        action = np.zeros( 10 )\n",
    "        action[ npr.randint(0,10) ] = 1\n",
    "        action += npr.randn( 10 )*0.1\n",
    "        action = softmax( action )\n",
    "        print('\\tSoft Noisy Action ',j,'=',action)\n",
    "        #### Apply Gumbel Softmax ####\n",
    "        temperature = 0.01\n",
    "        logProbAction = torch.log( avar(torch.FloatTensor(action)) ) \n",
    "        actiong = gumbel_softmax(logProbAction, temperature)\n",
    "        ##############################\n",
    "        print('\\tGumbel Action ',j,'=',actiong.data.numpy())\n",
    "        actionSet.append( actiong )\n",
    "        checkEnv.performAction( np.argmax(action) )\n",
    "        a = actiong  # avar( torch.FloatTensor(actiong) )\n",
    "        currState = f.forward( torch.cat([currState[0],a]).unsqueeze(0) )\n",
    "        print(\"Intermediate State\",j)\n",
    "        f.printState( currState[0] )\n",
    "    #checkEnv.performAction(np.argmax(a1))\n",
    "    #checkEnv.performAction(np.argmax(a2))\n",
    "    s_1 = checkEnv.getStateRep()\n",
    "    #inval = np.concatenate( (s_0,a1) )\n",
    "    #outval1 = f.forward( avar(torch.FloatTensor(inval).unsqueeze(0)) )\n",
    "    #print(outval1.shape)\n",
    "    #print(a2.shape)\n",
    "    #inval2 = np.concatenate( (outval1[0].data.numpy(),a2) )\n",
    "    #outval2 = f.forward( avar(torch.FloatTensor(inval2).unsqueeze(0)) )\n",
    "    for action in actionSet:\n",
    "        f.printAction(action)\n",
    "    print('Predicted')\n",
    "    f.printState( currState[0] )\n",
    "    print('Actual')\n",
    "    s1 = avar( torch.FloatTensor( s_1 ).unsqueeze(0) )\n",
    "    f.printState( s1[0] ) \n",
    "    print(\"Rough accuracy\", torch.sum( (currState - s1).pow(2) ).data[0] )\n",
    "    #print('Predicted',currState.data[0].numpy())\n",
    "    #print('Actual',s_1)\n",
    "    #outval1 = f.test(inval,s_1)\n",
    "    print('----\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
